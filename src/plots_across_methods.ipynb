{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5f265e-407a-40bd-92fb-a652091fd7ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL RANK  0\n",
      "PID of this process = 1113654\n",
      "device: cuda\n",
      "Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "distributed = False num_devices = 1 local rank = 0 world size = 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# custom functions #\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ffb659a-8154-4536-ab27-2d976da1bf4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: pretrained_subj01_40sess_hypatia_vd2\n",
      "--model_name=pretrained_subj01_40sess_hypatia_vd2 --data_path=/weka/proj-medarc/shared/mindeyev2_dataset --cache_dir=/weka/proj-medarc/shared/cache --all_recons_path=evals/pretrained_subj01_40sess_hypatia_vd2/pretrained_subj01_40sess_hypatia_vd2_all_recons_imagery.pt --mode imagery                         --imagery_data_path=/weka/proj-medarc/shared/umn-imagery --criteria=all\n"
     ]
    }
   ],
   "source": [
    "# If running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    methods = \"pretrained_subj01_40sess_hypatia_vd2,method2,method3\"\n",
    "    data_path = \"/weka/proj-medarc/shared/mindeyev2_dataset\"\n",
    "    criteria = \"all\"\n",
    "    print(\"Methods:\", methods)\n",
    "\n",
    "    jupyter_args = f\"--methods={methods} --data_path={data_path} --criteria={criteria}\"\n",
    "    print(jupyter_args)\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    \n",
    "    from IPython.display import clear_output  # Function to clear print outputs in cell\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "    # This allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    get_ipython().run_line_magic('autoreload', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8120cd-f226-4e2c-a6c5-3cd8ef6e9bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Compare methods based on metrics\")\n",
    "parser.add_argument(\n",
    "    \"--methods\", type=str, required=True,\n",
    "    help=\"Comma-separated list of method names to compare\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--data_path\", type=str, default=\"../dataset\",\n",
    "    help=\"Path to where metrics CSV files are stored\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--columns_to_normalize\", type=str, default='PixCorr,SSIM,AlexNet(2),AlexNet(5),InceptionV3,CLIP,EffNet-B,SwAV,FwdRetrieval,BwdRetrieval,Brain Corr. nsd_general,Brain Corr. V1,Brain Corr. V2,Brain Corr. V3,Brain Corr. V4,Brain Corr. higher_vis',\n",
    "    help=\"Comma-separated list of metric columns to normalize\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--criteria\", type=str, default=\"all\",\n",
    "    help=\"Criteria to use for averaging metrics. 'all' or comma-separated list of metrics\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--output_path\", type=str, default=\"../figs\",\n",
    "    help=\"Path to save the output scatter plot\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--output_file\", type=str, default=\"method_scatter_plot\",\n",
    "    help=\"Filename to save the output scatter plot\",\n",
    ")\n",
    "        \n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# Create global variables without the args prefix\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)\n",
    "\n",
    "criteria = criteria.replace(\"*\", \" \")\n",
    "methods = [method.strip() for method in methods.split(\",\")]\n",
    "columns_to_normalize = [col.strip() for col in columns_to_normalize.split(\",\")]\n",
    "\n",
    "# Seed all random functions\n",
    "seed = 42  # Set your seed value\n",
    "utils.seed_everything(seed)\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d66b33-b327-4895-a861-ecc6ccc51296",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997f9672-b74d-4dcf-b4d7-a593fdce9cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading tables for both modes\n",
    "modes = ['imagery', 'vision']\n",
    "dfs = []\n",
    "for method in methods:\n",
    "    for mode in modes:\n",
    "        metrics_file = f\"tables/{method}_all_recons_{mode}.csv\"\n",
    "        if not os.path.exists(metrics_file):\n",
    "            print(f\"Metrics file for method '{method}' and mode '{mode}' not found at {metrics_file}\")\n",
    "            sys.exit(1)\n",
    "        df = pd.read_csv(metrics_file, sep=\"\\t\")\n",
    "        df['method'] = method\n",
    "        df['mode'] = mode\n",
    "        dfs.append(df)\n",
    "\n",
    "all_metrics = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fc0d00-3851-450e-8c3c-3d5005fe075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded evals/pretrained_subj01_40sess_hypatia_vd2/pretrained_subj01_40sess_hypatia_vd2_all_recons_imagery.pt with shape torch.Size([18, 10, 3, 512, 512])\n",
      "Loaded tables/pretrained_subj01_40sess_hypatia_vd2_all_recons_imagery.csv\n",
      "Loaded evals/pretrained_subj02_40sess_hypatia_vd2/pretrained_subj02_40sess_hypatia_vd2_all_recons_imagery.pt with shape torch.Size([18, 10, 3, 512, 512])\n",
      "Loaded tables/pretrained_subj02_40sess_hypatia_vd2_all_recons_imagery.csv\n",
      "Loaded evals/pretrained_subj05_40sess_hypatia_vd2/pretrained_subj05_40sess_hypatia_vd2_all_recons_imagery.pt with shape torch.Size([18, 10, 3, 512, 512])\n",
      "Loaded tables/pretrained_subj05_40sess_hypatia_vd2_all_recons_imagery.csv\n",
      "Loaded evals/pretrained_subj07_40sess_hypatia_vd2/pretrained_subj07_40sess_hypatia_vd2_all_recons_imagery.pt with shape torch.Size([18, 10, 3, 512, 512])\n",
      "Loaded tables/pretrained_subj07_40sess_hypatia_vd2_all_recons_imagery.csv\n"
     ]
    }
   ],
   "source": [
    "# Check that columns_to_normalize exist in DataFrame\n",
    "missing_columns = [col for col in columns_to_normalize if col not in all_metrics.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Error: The following columns to normalize are missing from the data: {missing_columns}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Normalize specified columns across the entire dataset\n",
    "scaler = MinMaxScaler()\n",
    "all_metrics[columns_to_normalize] = scaler.fit_transform(all_metrics[columns_to_normalize])\n",
    "\n",
    "# Determine metrics to average\n",
    "if criteria == 'all':\n",
    "    metrics_to_average = columns_to_normalize\n",
    "else:\n",
    "    metrics_to_average = [col.strip() for col in criteria.split(\",\")]\n",
    "\n",
    "# Check that metrics_to_average exist in DataFrame\n",
    "missing_columns = [col for col in metrics_to_average if col not in all_metrics.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Error: The following metrics are missing from the data: {missing_columns}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Ensure 'method' is a categorical variable with the specified order\n",
    "all_metrics['method'] = pd.Categorical(all_metrics['method'], categories=methods, ordered=True)\n",
    "\n",
    "# Compute average normalized metric performance per method and mode\n",
    "method_mode_scores = all_metrics.groupby(['method', 'mode'])[metrics_to_average].mean()\n",
    "method_mode_scores['average_score'] = method_mode_scores.mean(axis=1)\n",
    "\n",
    "# Create a pivot table with methods as index and modes as columns\n",
    "average_scores = method_mode_scores['average_score'].unstack()\n",
    "\n",
    "# Reindex the pivot table to match the original 'methods' order\n",
    "average_scores = average_scores.reindex(methods)\n",
    "\n",
    "# Ensure that both 'imagery' and 'vision' modes are present for all methods\n",
    "average_scores = average_scores.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35405ae1-58a1-44a3-b856-58361fc2405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 0.0\n",
      "7.0 8.0\n",
      "2.0 6.0\n",
      "2.0 8.0\n",
      "1.0 3.0\n",
      "7.0 3.0\n",
      "2.0 6.0\n",
      "2.0 8.0\n",
      "2.0 4.0\n",
      "2.0 8.0\n",
      "2.0 1.0\n",
      "1.0 4.0\n"
     ]
    }
   ],
   "source": [
    "# Plot scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.subplot(111)\n",
    "colors = plt.cm.tab10.colors  # Get 10 colors from colormap\n",
    "\n",
    "# cmap = plt.cm.viridis  # You can change this to 'plasma', 'inferno', 'magma', 'hsv', etc.\n",
    "\n",
    "# Generate a list of colors using the colormap\n",
    "# colors = cmap(np.linspace(0, 1, len(average_scores.index)))\n",
    "\n",
    "for i, method in enumerate(average_scores.index):\n",
    "    x = average_scores.loc[method, 'vision']\n",
    "    y = average_scores.loc[method, 'imagery']\n",
    "    plt.scatter(x, y, color=colors[i % len(colors)], label=method, s=100)\n",
    "\n",
    "plt.xlabel('Vision Performance')\n",
    "plt.ylabel('Imagery Performance')\n",
    "plt.title(f'Imagery vs. Vision Performance\\n{output_file}')\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0 - 0.06, box.y0, box.width * 0.6, box.height])\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "output_file = os.path.join(output_path, f'{output_file}.png')\n",
    "print(f\"Saving scatter plot to {output_file}\")\n",
    "plt.savefig(output_file, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6ae46-3de9-4abb-ae2d-c8998d83d6f2",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
