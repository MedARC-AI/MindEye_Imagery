{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f0f4f3",
   "metadata": {},
   "source": [
    "# Import packages & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bad764b-45c1-45ce-a716-8d055e09821a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import webdataset as wds\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# SDXL unCLIP requires code from https://github.com/Stability-AI/generative-models/tree/main\n",
    "sys.path.append('generative_models/')\n",
    "import sgm\n",
    "from generative_models.sgm.modules.encoders.modules import FrozenOpenCLIPImageEmbedder # bigG embedder\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# custom functions #\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc5d2e32-6027-4a19-bef4-5ca068db35bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL RANK  0\n"
     ]
    }
   ],
   "source": [
    "### Multi-GPU config ###\n",
    "local_rank = os.getenv('RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(\"LOCAL RANK \", local_rank)  \n",
    "\n",
    "data_type = torch.float16 # change depending on your mixed_precision\n",
    "num_devices = torch.cuda.device_count()\n",
    "if num_devices==0: num_devices = 1\n",
    "\n",
    "# First use \"accelerate config\" in terminal and setup using deepspeed stage 2 with CPU offloading!\n",
    "accelerator = Accelerator(split_batches=False, mixed_precision=\"fp16\")\n",
    "if utils.is_interactive(): # set batch size here if using interactive notebook instead of submitting job\n",
    "    global_batch_size = batch_size = 8\n",
    "else:\n",
    "    global_batch_size = os.environ[\"GLOBAL_BATCH_SIZE\"]\n",
    "    batch_size = int(os.environ[\"GLOBAL_BATCH_SIZE\"]) // num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b767ab6f-d4a9-47a5-b3bf-f56bf6760c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID of this process = 2728105\n",
      "device: cuda\n",
      "Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "distributed = False num_devices = 1 local rank = 0 world size = 1 data_type = torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(\"PID of this process =\",os.getpid())\n",
    "device = accelerator.device\n",
    "print(\"device:\",device)\n",
    "world_size = accelerator.state.num_processes\n",
    "distributed = not accelerator.state.distributed_type == 'NO'\n",
    "num_devices = torch.cuda.device_count()\n",
    "if num_devices==0 or not distributed: num_devices = 1\n",
    "num_workers = num_devices\n",
    "print(accelerator.state)\n",
    "\n",
    "print(\"distributed =\",distributed, \"num_devices =\", num_devices, \"local rank =\", local_rank, \"world size =\", world_size, \"data_type =\", data_type)\n",
    "print = accelerator.print # only print if local_rank=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018b82b-c054-4463-9527-4b0c2a75bda6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b61fec7-72a0-4b67-86da-1375f1d9fbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: base\n",
      "--data_path=/weka/proj-fmri/shared/mindeyev2_dataset                     --cache_dir=/weka/proj-fmri/shared/cache                     --model_name=base                     --no-multi_subject --subj=1 --batch_size=8 --num_sessions=3                     --hidden_dim=1024 --clip_scale=1.                     --no-blurry_recon --blur_scale=.5                      --seq_past=0 --seq_future=0                     --use_prior --prior_scale=30                     --n_blocks=4 --max_lr=3e-4 --mixup_pct=.33 --num_epochs=150 --no-use_image_aug                     --ckpt_interval=1 --ckpt_saving --wandb_log --multisubject_ckpt=../train_logs/multisubject_subj01_1024_24bs_nolow\n"
     ]
    }
   ],
   "source": [
    "# if running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    model_name = \"base\"\n",
    "    print(\"model_name:\", model_name)\n",
    "    \n",
    "    # global_batch_size and batch_size should already be defined in the 2nd cell block\n",
    "    jupyter_args = f\"--data_path=/weka/proj-fmri/shared/mindeyev2_dataset \\\n",
    "                    --cache_dir=/weka/proj-fmri/shared/cache \\\n",
    "                    --model_name={model_name} \\\n",
    "                    --no-multi_subject --subj=1 --batch_size={batch_size} --num_sessions=3 \\\n",
    "                    --hidden_dim=1024 --clip_scale=1. \\\n",
    "                    --no-blurry_recon --blur_scale=.5  \\\n",
    "                    --seq_past=0 --seq_future=0 \\\n",
    "                    --use_prior --prior_scale=30 \\\n",
    "                    --n_blocks=4 --max_lr=3e-4 --mixup_pct=.33 --num_epochs=150 --no-use_image_aug \\\n",
    "                    --ckpt_interval=1 --ckpt_saving --wandb_log\"\n",
    "\n",
    "    print(jupyter_args)\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    \n",
    "    from IPython.display import clear_output # function to clear print outputs in cell\n",
    "    %load_ext autoreload \n",
    "    # this allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    %autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2028bdf0-2f41-46d9-b6e7-86b870dbf16c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj_list [1] num_sessions 3\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Model Training Configuration\")\n",
    "parser.add_argument(\n",
    "    \"--model_name\", type=str, default=\"testing\",\n",
    "    help=\"name of model, used for ckpt saving and wandb logging (if enabled)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--data_path\", type=str, default=os.getcwd(),\n",
    "    help=\"Path to where NSD data is stored / where to download it to\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--cache_dir\", type=str, default=os.getcwd(),\n",
    "    help=\"Path to where misc. files downloaded from huggingface are stored. Defaults to current src directory.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--subj\",type=int, default=1, choices=[1,2,3,4,5,6,7,8],\n",
    "    help=\"Validate on which subject?\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--multisubject_ckpt\", type=str, default=None,\n",
    "    help=\"Path to pre-trained multisubject model to finetune a single subject from. multisubject must be False.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_sessions\", type=int, default=1,\n",
    "    help=\"Number of training sessions to include\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_prior\",action=argparse.BooleanOptionalAction,default=True,\n",
    "    help=\"whether to train diffusion prior (True) or just rely on retrieval part of the pipeline (False)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--visualize_prior\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"output visualizations from unCLIP every ckpt_interval (requires much more memory!)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", type=int, default=16,\n",
    "    help=\"Batch size can be increased by 10x if only training retreival submodule and not diffusion prior\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_log\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to log to wandb\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--resume_from_ckpt\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"if not using wandb and want to resume from a ckpt\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_project\",type=str,default=\"stability\",\n",
    "    help=\"wandb project name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--mixup_pct\",type=float,default=.33,\n",
    "    help=\"proportion of way through training when to switch from BiMixCo to SoftCLIP\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--blurry_recon\",action=argparse.BooleanOptionalAction,default=True,\n",
    "    help=\"whether to output blurry reconstructions\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--blur_scale\",type=float,default=.5,\n",
    "    help=\"multiply loss from blurry recons by this number\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--clip_scale\",type=float,default=1.,\n",
    "    help=\"multiply contrastive loss by this number\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--prior_scale\",type=float,default=30,\n",
    "    help=\"multiply diffusion prior loss by this\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_image_aug\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to use image augmentation\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_epochs\",type=int,default=150,\n",
    "    help=\"number of epochs of training\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--multi_subject\",action=argparse.BooleanOptionalAction,default=False,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--new_test\",action=argparse.BooleanOptionalAction,default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n_blocks\",type=int,default=4,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden_dim\",type=int,default=1024,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seq_past\",type=int,default=0,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seq_future\",type=int,default=0,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr_scheduler_type\",type=str,default='cycle',choices=['cycle','linear'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ckpt_saving\",action=argparse.BooleanOptionalAction,default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ckpt_interval\",type=int,default=5,\n",
    "    help=\"save backup ckpt and reconstruct every x epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\",type=int,default=42,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_lr\",type=float,default=3e-4,\n",
    ")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# create global variables without the args prefix\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)\n",
    "    \n",
    "# seed all random functions\n",
    "utils.seed_everything(seed)\n",
    "\n",
    "outdir = os.path.abspath(f'../train_logs/{model_name}')\n",
    "if not os.path.exists(outdir) and ckpt_saving:\n",
    "    os.makedirs(outdir,exist_ok=True)\n",
    "    \n",
    "if use_image_aug or blurry_recon:\n",
    "    import kornia\n",
    "    from kornia.augmentation.container import AugmentationSequential\n",
    "if use_image_aug:\n",
    "    img_augment = AugmentationSequential(\n",
    "        kornia.augmentation.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.3),\n",
    "        same_on_batch=False,\n",
    "        data_keys=[\"input\"],\n",
    "    )\n",
    "    \n",
    "if multi_subject:\n",
    "    subj_list = np.arange(1,9)\n",
    "    subj_list = subj_list[subj_list != subj]\n",
    "else:\n",
    "    subj_list = [subj]\n",
    "\n",
    "print(\"subj_list\", subj_list, \"num_sessions\", num_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d13c25-1369-4c49-81d4-83d713586096",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prep data, models, and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c023f24-5233-4a15-a2f5-78487b3a8546",
   "metadata": {},
   "source": [
    "### Creating wds dataloader, preload betas and all 73k possible images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aefe7c27-ab39-4b2c-90f4-480f4087b7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dividing batch size by subj_list, which will then be concatenated across subj during training...\n",
      "batch_size = 8 num_iterations_per_epoch = 281 num_samples_per_epoch = 2250\n"
     ]
    }
   ],
   "source": [
    "def my_split_by_node(urls): return urls\n",
    "num_voxels_list = []\n",
    "\n",
    "if multi_subject:\n",
    "    nsessions_allsubj=np.array([40, 40, 32, 30, 40, 32, 40, 30])\n",
    "    num_samples_per_epoch = (750*40) // num_devices \n",
    "else:\n",
    "    num_samples_per_epoch = (750*num_sessions) // num_devices \n",
    "\n",
    "print(\"dividing batch size by subj_list, which will then be concatenated across subj during training...\") \n",
    "batch_size = batch_size // len(subj_list)\n",
    "\n",
    "num_iterations_per_epoch = num_samples_per_epoch // (batch_size*len(subj_list))\n",
    "\n",
    "print(\"batch_size =\", batch_size, \"num_iterations_per_epoch =\",num_iterations_per_epoch, \"num_samples_per_epoch =\",num_samples_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81084834-035f-4465-ad59-59e6b806a2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 3 sessions\n",
      "/weka/proj-fmri/shared/mindeyev2_dataset/wds/subj01/train/{0..2}.tar\n",
      "num_voxels for subj01: 15724\n",
      "Loaded all subj train dls and betas!\n",
      "\n",
      "/weka/proj-fmri/shared/mindeyev2_dataset/wds/subj01/new_test/0.tar\n",
      "Loaded test dl for subj1!\n",
      "\n",
      "currently using 1 seq_len (chose 0 past behav and 0 future behav)\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "train_dl = {}\n",
    "num_voxels = {}\n",
    "voxels = {}\n",
    "for s in subj_list:\n",
    "    print(f\"Training with {num_sessions} sessions\")\n",
    "    if multi_subject:\n",
    "        train_url = f\"{data_path}/wds/subj0{s}/train/\" + \"{0..\" + f\"{nsessions_allsubj[s-1]-1}\" + \"}.tar\"\n",
    "    else:\n",
    "        train_url = f\"{data_path}/wds/subj0{s}/train/\" + \"{0..\" + f\"{num_sessions-1}\" + \"}.tar\"\n",
    "    print(train_url)\n",
    "    \n",
    "    train_data[f'subj0{s}'] = wds.WebDataset(train_url,resampled=True,nodesplitter=my_split_by_node)\\\n",
    "                        .shuffle(750, initial=1500, rng=random.Random(42))\\\n",
    "                        .decode(\"torch\")\\\n",
    "                        .rename(behav=\"behav.npy\", past_behav=\"past_behav.npy\", future_behav=\"future_behav.npy\", olds_behav=\"olds_behav.npy\")\\\n",
    "                        .to_tuple(*[\"behav\", \"past_behav\", \"future_behav\", \"olds_behav\"])\n",
    "    train_dl[f'subj0{s}'] = torch.utils.data.DataLoader(train_data[f'subj0{s}'], batch_size=batch_size, shuffle=False, drop_last=True, pin_memory=True)\n",
    "\n",
    "    f = h5py.File(f'{data_path}/betas_all_subj0{s}_fp32_renorm.hdf5', 'r')\n",
    "    betas = f['betas'][:]\n",
    "    betas = torch.Tensor(betas).to(\"cpu\").to(data_type)\n",
    "    num_voxels_list.append(betas[0].shape[-1])\n",
    "    num_voxels[f'subj0{s}'] = betas[0].shape[-1]\n",
    "    voxels[f'subj0{s}'] = betas\n",
    "    print(f\"num_voxels for subj0{s}: {num_voxels[f'subj0{s}']}\")\n",
    "\n",
    "print(\"Loaded all subj train dls and betas!\\n\")\n",
    "\n",
    "# Validate only on one subject\n",
    "if multi_subject: \n",
    "    subj = subj_list[0] # cant validate on the actual held out person so picking first in subj_list\n",
    "if not new_test: # using old test set from before full dataset released (used in original MindEye paper)\n",
    "    if subj==3:\n",
    "        num_test=2113\n",
    "    elif subj==4:\n",
    "        num_test=1985\n",
    "    elif subj==6:\n",
    "        num_test=2113\n",
    "    elif subj==8:\n",
    "        num_test=1985\n",
    "    else:\n",
    "        num_test=2770\n",
    "    test_url = f\"{data_path}/wds/subj0{subj}/test/\" + \"0.tar\"\n",
    "elif new_test: # using larger test set from after full dataset released\n",
    "    if subj==3:\n",
    "        num_test=2371\n",
    "    elif subj==4:\n",
    "        num_test=2188\n",
    "    elif subj==6:\n",
    "        num_test=2371\n",
    "    elif subj==8:\n",
    "        num_test=2188\n",
    "    else:\n",
    "        num_test=3000\n",
    "    test_url = f\"{data_path}/wds/subj0{subj}/new_test/\" + \"0.tar\"\n",
    "print(test_url)\n",
    "test_data = wds.WebDataset(test_url,resampled=False,nodesplitter=my_split_by_node)\\\n",
    "                    .shuffle(750, initial=1500, rng=random.Random(42))\\\n",
    "                    .decode(\"torch\")\\\n",
    "                    .rename(behav=\"behav.npy\", past_behav=\"past_behav.npy\", future_behav=\"future_behav.npy\", olds_behav=\"olds_behav.npy\")\\\n",
    "                    .to_tuple(*[\"behav\", \"past_behav\", \"future_behav\", \"olds_behav\"])\n",
    "test_dl = torch.utils.data.DataLoader(test_data, batch_size=num_test, shuffle=False, drop_last=True, pin_memory=True)\n",
    "print(f\"Loaded test dl for subj{subj}!\\n\")\n",
    "\n",
    "seq_len = seq_past + 1 + seq_future\n",
    "print(f\"currently using {seq_len} seq_len (chose {seq_past} past behav and {seq_future} future behav)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13b4b84-094c-4b5b-bace-26c155aa6181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all 73k possible NSD images to cpu! torch.Size([73000, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Load 73k NSD images\n",
    "f = h5py.File(f'{data_path}/coco_images_224_float16.hdf5', 'r')\n",
    "images = f['images'][:] # if you go OOM you can remove the [:] so it isnt preloaded to cpu! (will require a few edits elsewhere tho)\n",
    "images = torch.Tensor(images).to(\"cpu\").to(data_type)\n",
    "print(\"Loaded all 73k possible NSD images to cpu!\", images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec4517-dbdf-4ece-98f6-4714d5de4e15",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6160e-1ee8-4da7-a755-9dbb452a6fa5",
   "metadata": {},
   "source": [
    "### CLIP image embeddings  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0420dc0-199e-4c1a-857d-b1747058b467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a214ce55a5c84d13b00c53cb96b3d111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_pytorch_model.bin:   0%|          | 0.00/10.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_img_embedder = FrozenOpenCLIPImageEmbedder(\n",
    "    arch=\"ViT-bigG-14\",\n",
    "    version=\"laion2b_s39b_b160k\",\n",
    "    output_tokens=True,\n",
    "    only_tokens=True,\n",
    ")\n",
    "clip_img_embedder.to(device)\n",
    "\n",
    "clip_seq_dim = 256\n",
    "clip_emb_dim = 1664"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79bd38-6990-4504-8d45-4a68d57d8885",
   "metadata": {},
   "source": [
    "### SD VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01baff79-8114-482b-b115-6f05aa8ad691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if blurry_recon:\n",
    "    from diffusers import AutoencoderKL    \n",
    "    autoenc = AutoencoderKL(\n",
    "        down_block_types=['DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D'],\n",
    "        up_block_types=['UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D'],\n",
    "        block_out_channels=[128, 256, 512, 512],\n",
    "        layers_per_block=2,\n",
    "        sample_size=256,\n",
    "    )\n",
    "    ckpt = torch.load(f'{cache_dir}/sd_image_var_autoenc.pth')\n",
    "    autoenc.load_state_dict(ckpt)\n",
    "    \n",
    "    autoenc.eval()\n",
    "    autoenc.requires_grad_(False)\n",
    "    autoenc.to(device)\n",
    "    utils.count_params(autoenc)\n",
    "    \n",
    "    from autoencoder.convnext import ConvnextXL\n",
    "    cnx = ConvnextXL(f'{cache_dir}/convnext_xlarge_alpha0.75_fullckpt.pth')\n",
    "    cnx.requires_grad_(False)\n",
    "    cnx.eval()\n",
    "    cnx.to(device)\n",
    "    \n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).to(device).reshape(1,3,1,1)\n",
    "    std = torch.tensor([0.228, 0.224, 0.225]).to(device).reshape(1,3,1,1)\n",
    "    \n",
    "    blur_augs = AugmentationSequential(\n",
    "        kornia.augmentation.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1, p=0.8),\n",
    "        kornia.augmentation.RandomGrayscale(p=0.1),\n",
    "        kornia.augmentation.RandomSolarize(p=0.1),\n",
    "        kornia.augmentation.RandomResizedCrop((224,224), scale=(.9,.9), ratio=(1,1), p=1.0),\n",
    "        data_keys=[\"input\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e5e4a-f697-4b2c-88fc-01f6a54886c0",
   "metadata": {},
   "source": [
    "### MindEye modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c44c271b-173f-472e-b059-a2eda0f4c4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MindEyeModule()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MindEyeModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MindEyeModule, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        \n",
    "model = MindEyeModule()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "038a5d61-4769-40b9-a004-f4e7b5b38bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "16,102,400 total\n",
      "16,102,400 trainable\n",
      "param counts:\n",
      "16,102,400 total\n",
      "16,102,400 trainable\n",
      "torch.Size([2, 1, 15724]) torch.Size([2, 1, 1024])\n"
     ]
    }
   ],
   "source": [
    "class RidgeRegression(torch.nn.Module):\n",
    "    # make sure to add weight_decay when initializing optimizer\n",
    "    def __init__(self, input_sizes, out_features, seq_len): \n",
    "        super(RidgeRegression, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.linears = torch.nn.ModuleList([\n",
    "                torch.nn.Linear(input_size, out_features) for input_size in input_sizes\n",
    "            ])\n",
    "    def forward(self, x, subj_idx):\n",
    "        out = torch.cat([self.linears[subj_idx](x[:,seq]).unsqueeze(1) for seq in range(seq_len)], dim=1)\n",
    "        return out\n",
    "        \n",
    "model.ridge = RidgeRegression(num_voxels_list, out_features=hidden_dim, seq_len=seq_len)\n",
    "utils.count_params(model.ridge)\n",
    "utils.count_params(model)\n",
    "\n",
    "# test on subject 1 with fake data\n",
    "b = torch.randn((2,seq_len,num_voxels_list[0]))\n",
    "print(b.shape, model.ridge(b,0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b8de65a-6d3b-4248-bea9-9b6f4d562321",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "453,360,280 total\n",
      "453,360,280 trainable\n",
      "param counts:\n",
      "469,462,680 total\n",
      "469,462,680 trainable\n",
      "b.shape torch.Size([2, 1, 1024])\n",
      "torch.Size([2, 256, 1664]) torch.Size([2, 256, 1664]) torch.Size([1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from models import BrainNetwork\n",
    "model.backbone = BrainNetwork(h=hidden_dim, in_dim=hidden_dim, seq_len=seq_len, n_blocks=n_blocks,\n",
    "                          clip_size=clip_emb_dim, out_dim=clip_emb_dim*clip_seq_dim, \n",
    "                          blurry_recon=blurry_recon, clip_scale=clip_scale)\n",
    "utils.count_params(model.backbone)\n",
    "utils.count_params(model)\n",
    "\n",
    "# test that the model works on some fake data\n",
    "b = torch.randn((2,seq_len,hidden_dim))\n",
    "print(\"b.shape\",b.shape)\n",
    "\n",
    "backbone_, clip_, blur_ = model.backbone(b)\n",
    "print(backbone_.shape, clip_.shape, blur_[0].shape, blur_[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397c0d7-52a3-4153-823b-c27d2eb3eeba",
   "metadata": {},
   "source": [
    "### Adding diffusion prior + unCLIP if use_prior=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69965344-9346-4592-9cc5-e537e31d5fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "259,865,216 total\n",
      "259,865,200 trainable\n",
      "param counts:\n",
      "729,327,896 total\n",
      "729,327,880 trainable\n"
     ]
    }
   ],
   "source": [
    "if use_prior:\n",
    "    from models import *\n",
    "\n",
    "    # setup diffusion prior network\n",
    "    out_dim = clip_emb_dim\n",
    "    depth = 6\n",
    "    dim_head = 52\n",
    "    heads = clip_emb_dim//52 # heads * dim_head = clip_emb_dim\n",
    "    timesteps = 100\n",
    "\n",
    "    prior_network = PriorNetwork(\n",
    "            dim=out_dim,\n",
    "            depth=depth,\n",
    "            dim_head=dim_head,\n",
    "            heads=heads,\n",
    "            causal=False,\n",
    "            num_tokens = clip_seq_dim,\n",
    "            learned_query_mode=\"pos_emb\"\n",
    "        )\n",
    "\n",
    "    model.diffusion_prior = BrainDiffusionPrior(\n",
    "        net=prior_network,\n",
    "        image_embed_dim=out_dim,\n",
    "        condition_on_text_encodings=False,\n",
    "        timesteps=timesteps,\n",
    "        cond_drop_prob=0.2,\n",
    "        image_embed_scale=None,\n",
    "    )\n",
    "    \n",
    "    utils.count_params(model.diffusion_prior)\n",
    "    utils.count_params(model)\n",
    "    \n",
    "    # prep unCLIP\n",
    "    if visualize_prior:\n",
    "        from generative_models.sgm.models.diffusion import DiffusionEngine\n",
    "        from omegaconf import OmegaConf\n",
    "        \n",
    "        config = OmegaConf.load(\"generative_models/configs/unclip6.yaml\")\n",
    "        config = OmegaConf.to_container(config, resolve=True)\n",
    "        unclip_params = config[\"model\"][\"params\"]\n",
    "        network_config = unclip_params[\"network_config\"]\n",
    "        denoiser_config = unclip_params[\"denoiser_config\"]\n",
    "        first_stage_config = unclip_params[\"first_stage_config\"]\n",
    "        conditioner_config = unclip_params[\"conditioner_config\"]\n",
    "        sampler_config = unclip_params[\"sampler_config\"]\n",
    "        scale_factor = unclip_params[\"scale_factor\"]\n",
    "        disable_first_stage_autocast = unclip_params[\"disable_first_stage_autocast\"]\n",
    "        offset_noise_level = unclip_params[\"loss_fn_config\"][\"params\"][\"offset_noise_level\"]\n",
    "\n",
    "        first_stage_config['target'] = 'sgm.models.autoencoder.AutoencoderKL'\n",
    "        sampler_config['params']['num_steps'] = 38\n",
    "\n",
    "        diffusion_engine = DiffusionEngine(network_config=network_config,\n",
    "                               denoiser_config=denoiser_config,\n",
    "                               first_stage_config=first_stage_config,\n",
    "                               conditioner_config=conditioner_config,\n",
    "                               sampler_config=sampler_config,\n",
    "                               scale_factor=scale_factor,\n",
    "                               disable_first_stage_autocast=disable_first_stage_autocast)\n",
    "        # set to inference\n",
    "        diffusion_engine.eval().requires_grad_(False)\n",
    "        diffusion_engine.to(device)\n",
    "\n",
    "        ckpt_path = f'{cache_dir}/unclip6_epoch0_step110000.ckpt'\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        diffusion_engine.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "        image = images[:1].to(device)\n",
    "        batch={\"jpg\": image,\n",
    "              \"original_size_as_tuple\": torch.ones(image.shape[0], 2).to(device) * 768,\n",
    "              \"crop_coords_top_left\": torch.zeros(image.shape[0], 2).to(device)}\n",
    "        out = diffusion_engine.conditioner(batch)\n",
    "        vector_suffix = out[\"vector\"].to(device)\n",
    "        print(\"vector_suffix\", vector_suffix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25271a-2209-400c-8026-df3b8ddc1eef",
   "metadata": {},
   "source": [
    "### Setup optimizer / lr / ckpt saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e14d0482-dc42-43b9-9ce1-953c32f2c9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps 42150\n",
      "\n",
      "Done with model preparations!\n",
      "param counts:\n",
      "729,327,896 total\n",
      "729,327,880 trainable\n"
     ]
    }
   ],
   "source": [
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "opt_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.ridge.named_parameters()], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "]\n",
    "if use_prior:\n",
    "    opt_grouped_parameters.extend([\n",
    "        {'params': [p for n, p in model.diffusion_prior.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "        {'params': [p for n, p in model.diffusion_prior.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ])\n",
    "\n",
    "optimizer = torch.optim.AdamW(opt_grouped_parameters, lr=max_lr)\n",
    "\n",
    "if lr_scheduler_type == 'linear':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer,\n",
    "        total_iters=int(np.floor(num_epochs*num_iterations_per_epoch)),\n",
    "        last_epoch=-1\n",
    "    )\n",
    "elif lr_scheduler_type == 'cycle':\n",
    "    total_steps=int(np.floor(num_epochs*num_iterations_per_epoch))\n",
    "    print(\"total_steps\", total_steps)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=max_lr,\n",
    "        total_steps=total_steps,\n",
    "        final_div_factor=1000,\n",
    "        last_epoch=-1, pct_start=2/num_epochs\n",
    "    )\n",
    "    \n",
    "def save_ckpt(tag):\n",
    "    ckpt_path = outdir+f'/{tag}.pth'\n",
    "    if accelerator.is_main_process:\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': unwrapped_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'train_losses': losses,\n",
    "            'test_losses': test_losses,\n",
    "            'lrs': lrs,\n",
    "            }, ckpt_path)\n",
    "    print(f\"\\n---saved {outdir}/{tag} ckpt!---\\n\")\n",
    "\n",
    "def load_ckpt(tag,load_lr=True,load_optimizer=True,load_epoch=True,strict=True,outdir=outdir,multisubj_loading=False): \n",
    "    print(f\"\\n---loading {outdir}/{tag}.pth ckpt---\\n\")\n",
    "    checkpoint = torch.load(outdir+'/last.pth', map_location='cpu')\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    if multisubj_loading: # remove incompatible ridge layer that will otherwise error\n",
    "        state_dict.pop('ridge.linears.0.weight',None)\n",
    "    model.load_state_dict(state_dict, strict=strict)\n",
    "    if load_epoch:\n",
    "        globals()[\"epoch\"] = checkpoint['epoch']\n",
    "        print(\"Epoch\",epoch)\n",
    "    if load_optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if load_lr:\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    del checkpoint\n",
    "\n",
    "print(\"\\nDone with model preparations!\")\n",
    "num_params = utils.count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f458b-35b8-49f2-b6db-80296cece730",
   "metadata": {},
   "source": [
    "# Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a25a662-daa8-4de9-9233-8364800fcb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb mental-imagery run base\n",
      "wandb_config:\n",
      " {'model_name': 'base', 'global_batch_size': 8, 'batch_size': 8, 'num_epochs': 150, 'num_sessions': 3, 'num_params': 729327880, 'clip_scale': 1.0, 'prior_scale': 30.0, 'blur_scale': 0.5, 'use_image_aug': False, 'max_lr': 0.0003, 'mixup_pct': 0.33, 'num_samples_per_epoch': 2250, 'num_test': 3000, 'ckpt_interval': 1, 'ckpt_saving': True, 'seed': 42, 'distributed': False, 'num_devices': 1, 'world_size': 1, 'train_url': '/weka/proj-fmri/shared/mindeyev2_dataset/wds/subj01/train/{0..2}.tar', 'test_url': '/weka/proj-fmri/shared/mindeyev2_dataset/wds/subj01/new_test/0.tar'}\n",
      "wandb_id: base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjonxuxu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/weka/proj-fmri/jonxu/MindEye_Imagery/src/wandb/run-20240513_231852-base</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jonxuxu/mental-imagery/runs/base' target=\"_blank\">base</a></strong> to <a href='https://wandb.ai/jonxuxu/mental-imagery' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jonxuxu/mental-imagery' target=\"_blank\">https://wandb.ai/jonxuxu/mental-imagery</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jonxuxu/mental-imagery/runs/base' target=\"_blank\">https://wandb.ai/jonxuxu/mental-imagery/runs/base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if local_rank==0 and wandb_log: # only use main process for wandb logging\n",
    "    import wandb\n",
    "    wandb_project = 'mental-imagery'\n",
    "    print(f\"wandb {wandb_project} run {model_name}\")\n",
    "    # need to configure wandb beforehand in terminal with \"wandb init\"!\n",
    "    wandb_config = {\n",
    "      \"model_name\": model_name,\n",
    "      \"global_batch_size\": global_batch_size,\n",
    "      \"batch_size\": batch_size,\n",
    "      \"num_epochs\": num_epochs,\n",
    "      \"num_sessions\": num_sessions,\n",
    "      \"num_params\": num_params,\n",
    "      \"clip_scale\": clip_scale,\n",
    "      \"prior_scale\": prior_scale,\n",
    "      \"blur_scale\": blur_scale,\n",
    "      \"use_image_aug\": use_image_aug,\n",
    "      \"max_lr\": max_lr,\n",
    "      \"mixup_pct\": mixup_pct,\n",
    "      \"num_samples_per_epoch\": num_samples_per_epoch,\n",
    "      \"num_test\": num_test,\n",
    "      \"ckpt_interval\": ckpt_interval,\n",
    "      \"ckpt_saving\": ckpt_saving,\n",
    "      \"seed\": seed,\n",
    "      \"distributed\": distributed,\n",
    "      \"num_devices\": num_devices,\n",
    "      \"world_size\": world_size,\n",
    "      \"train_url\": train_url,\n",
    "      \"test_url\": test_url,\n",
    "    }\n",
    "    print(\"wandb_config:\\n\",wandb_config)\n",
    "    print(\"wandb_id:\",model_name)\n",
    "    wandb.init(\n",
    "        id=model_name,\n",
    "        project=wandb_project,\n",
    "        name=model_name,\n",
    "        config=wandb_config,\n",
    "        resume=\"allow\",\n",
    "    )\n",
    "else:\n",
    "    wandb_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5690151-2131-4918-b750-e869cbd1a8a8",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12de6387-6e18-4e4b-b5ce-a847d625330a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "losses, test_losses, lrs = [], [], []\n",
    "best_test_loss = 1e9\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "607a7c7b-fe5e-41a4-80bf-d2814b3a57cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---loading ../train_logs/multisubject_subj01_1024_24bs_nolow/last.pth ckpt---\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../train_logs/multisubject_subj01_1024_24bs_nolow/last.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load multisubject stage1 ckpt if set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multisubject_ckpt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resume_from_ckpt:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mload_ckpt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moutdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultisubject_ckpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mload_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mload_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mload_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mmultisubj_loading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 50\u001b[0m, in \u001b[0;36mload_ckpt\u001b[0;34m(tag, load_lr, load_optimizer, load_epoch, strict, outdir, multisubj_loading)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_ckpt\u001b[39m(tag,load_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,load_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,load_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,outdir\u001b[38;5;241m=\u001b[39moutdir,multisubj_loading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth ckpt---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutdir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/last.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multisubj_loading: \u001b[38;5;66;03m# remove incompatible ridge layer that will otherwise error\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/imagery/lib/python3.11/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/mambaforge/envs/imagery/lib/python3.11/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/mambaforge/envs/imagery/lib/python3.11/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../train_logs/multisubject_subj01_1024_24bs_nolow/last.pth'"
     ]
    }
   ],
   "source": [
    "# load multisubject stage1 ckpt if set\n",
    "if multisubject_ckpt is not None and not resume_from_ckpt:\n",
    "    load_ckpt(\"last\",outdir=multisubject_ckpt,load_lr=False,load_optimizer=False,load_epoch=False,strict=False,multisubj_loading=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5453c316-0cb0-4bee-8585-f44dff746e1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load saved ckpt model weights into current model\n",
    "if resume_from_ckpt:\n",
    "    load_ckpt(\"last\",load_lr=True,load_optimizer=True,load_epoch=True)\n",
    "elif wandb_log:\n",
    "    if wandb.run.resumed:\n",
    "        load_ckpt(\"last\",load_lr=True,load_optimizer=True,load_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99f09f76-4481-4133-b09a-a22b10dbc0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dls = [train_dl[f'subj0{s}'] for s in subj_list]\n",
    "\n",
    "model, optimizer, *train_dls, lr_scheduler = accelerator.prepare(model, optimizer, *train_dls, lr_scheduler)\n",
    "# leaving out test_dl since we will only have local_rank 0 device do evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60be0d5f-3e94-4612-9373-61b53d836393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base starting with epoch 0 / 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 0/150 [01:07<?, ?it/s, test/blurry_pixcorr=0, test/loss=28.1, test/loss_clip_total=4.98, test/loss_prior=0.77, test/num_steps=1, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.0367, test/test_fwd_pct_correct=0.19, train/blurry_pixcorr=0, train/bwd_pct_correct=0.233, train/fwd_pct_correct=0.396, train/loss=29.6, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=1.73, train/loss_prior=0.93, train/lr=0.000152, train/num_steps=281, train/recon_cossim=0.259, train/recon_mse=0.93]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "[2024-05-13 23:22:14,977] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 1/150 [01:59<3:15:44, 78.82s/it, test/blurry_pixcorr=0, test/loss=23.1, test/loss_clip_total=3.54, test/loss_prior=0.651, test/num_steps=2, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.12, test/test_fwd_pct_correct=0.277, train/blurry_pixcorr=0, train/bwd_pct_correct=0.461, train/fwd_pct_correct=0.591, train/loss=22, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=1.07, train/loss_prior=0.698, train/lr=0.0003, train/num_steps=562, train/recon_cossim=0.426, train/recon_mse=0.698]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 2/150 [02:50<2:31:40, 61.49s/it, test/blurry_pixcorr=0, test/loss=18.1, test/loss_clip_total=2.89, test/loss_prior=0.508, test/num_steps=3, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.24, test/test_fwd_pct_correct=0.377, train/blurry_pixcorr=0, train/bwd_pct_correct=0.628, train/fwd_pct_correct=0.669, train/loss=17.7, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.606, train/loss_prior=0.57, train/lr=0.0003, train/num_steps=843, train/recon_cossim=0.535, train/recon_mse=0.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | 3/150 [03:40<2:19:34, 56.97s/it, test/blurry_pixcorr=0, test/loss=16.9, test/loss_clip_total=2.45, test/loss_prior=0.481, test/num_steps=4, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.303, test/test_fwd_pct_correct=0.547, train/blurry_pixcorr=0, train/bwd_pct_correct=0.706, train/fwd_pct_correct=0.71, train/loss=16.3, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.481, train/loss_prior=0.527, train/lr=0.0003, train/num_steps=1124, train/recon_cossim=0.575, train/recon_mse=0.527]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 4/150 [04:30<2:11:34, 54.07s/it, test/blurry_pixcorr=0, test/loss=17.1, test/loss_clip_total=2.36, test/loss_prior=0.492, test/num_steps=5, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.333, test/test_fwd_pct_correct=0.553, train/blurry_pixcorr=0, train/bwd_pct_correct=0.73, train/fwd_pct_correct=0.718, train/loss=15.7, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.381, train/loss_prior=0.511, train/lr=0.0003, train/num_steps=1405, train/recon_cossim=0.592, train/recon_mse=0.511]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | 5/150 [05:20<2:07:11, 52.63s/it, test/blurry_pixcorr=0, test/loss=15.8, test/loss_clip_total=2.28, test/loss_prior=0.451, test/num_steps=6, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.37, test/test_fwd_pct_correct=0.577, train/blurry_pixcorr=0, train/bwd_pct_correct=0.754, train/fwd_pct_correct=0.737, train/loss=15.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.366, train/loss_prior=0.494, train/lr=0.000299, train/num_steps=1686, train/recon_cossim=0.608, train/recon_mse=0.494]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | 6/150 [06:10<2:04:14, 51.77s/it, test/blurry_pixcorr=0, test/loss=15.4, test/loss_clip_total=2.13, test/loss_prior=0.441, test/num_steps=7, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.433, test/test_fwd_pct_correct=0.59, train/blurry_pixcorr=0, train/bwd_pct_correct=0.765, train/fwd_pct_correct=0.736, train/loss=15.1, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.359, train/loss_prior=0.49, train/lr=0.000299, train/num_steps=1967, train/recon_cossim=0.613, train/recon_mse=0.49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 7/150 [06:59<2:01:37, 51.03s/it, test/blurry_pixcorr=0, test/loss=16.6, test/loss_clip_total=2.22, test/loss_prior=0.48, test/num_steps=8, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.397, test/test_fwd_pct_correct=0.613, train/blurry_pixcorr=0, train/bwd_pct_correct=0.766, train/fwd_pct_correct=0.753, train/loss=14.3, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.341, train/loss_prior=0.464, train/lr=0.000299, train/num_steps=2248, train/recon_cossim=0.635, train/recon_mse=0.464]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 8/150 [07:48<1:59:26, 50.47s/it, test/blurry_pixcorr=0, test/loss=18.6, test/loss_clip_total=2.05, test/loss_prior=0.552, test/num_steps=9, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.42, test/test_fwd_pct_correct=0.64, train/blurry_pixcorr=0, train/bwd_pct_correct=0.756, train/fwd_pct_correct=0.722, train/loss=14.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.319, train/loss_prior=0.474, train/lr=0.000298, train/num_steps=2529, train/recon_cossim=0.629, train/recon_mse=0.474]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | 9/150 [08:40<1:57:35, 50.04s/it, test/blurry_pixcorr=0, test/loss=15.9, test/loss_clip_total=2.03, test/loss_prior=0.462, test/num_steps=10, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.46, test/test_fwd_pct_correct=0.623, train/blurry_pixcorr=0, train/bwd_pct_correct=0.763, train/fwd_pct_correct=0.728, train/loss=14, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.331, train/loss_prior=0.457, train/lr=0.000298, train/num_steps=2810, train/recon_cossim=0.642, train/recon_mse=0.457]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | 10/150 [09:30<1:58:08, 50.63s/it, test/blurry_pixcorr=0, test/loss=16.5, test/loss_clip_total=2.04, test/loss_prior=0.48, test/num_steps=11, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.453, test/test_fwd_pct_correct=0.587, train/blurry_pixcorr=0, train/bwd_pct_correct=0.764, train/fwd_pct_correct=0.726, train/loss=13.6, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.321, train/loss_prior=0.444, train/lr=0.000297, train/num_steps=3091, train/recon_cossim=0.653, train/recon_mse=0.444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 11/150 [10:19<1:56:40, 50.36s/it, test/blurry_pixcorr=0, test/loss=16.1, test/loss_clip_total=1.93, test/loss_prior=0.472, test/num_steps=12, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.553, test/test_fwd_pct_correct=0.627, train/blurry_pixcorr=0, train/bwd_pct_correct=0.763, train/fwd_pct_correct=0.727, train/loss=13.3, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.306, train/loss_prior=0.434, train/lr=0.000297, train/num_steps=3372, train/recon_cossim=0.661, train/recon_mse=0.434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 12/150 [11:09<1:55:20, 50.15s/it, test/blurry_pixcorr=0, test/loss=15.9, test/loss_clip_total=1.88, test/loss_prior=0.468, test/num_steps=13, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.55, test/test_fwd_pct_correct=0.623, train/blurry_pixcorr=0, train/bwd_pct_correct=0.758, train/fwd_pct_correct=0.725, train/loss=13.7, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.32, train/loss_prior=0.447, train/lr=0.000296, train/num_steps=3653, train/recon_cossim=0.652, train/recon_mse=0.447]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | 13/150 [11:59<1:54:17, 50.06s/it, test/blurry_pixcorr=0, test/loss=15, test/loss_clip_total=1.98, test/loss_prior=0.435, test/num_steps=14, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.477, test/test_fwd_pct_correct=0.617, train/blurry_pixcorr=0, train/bwd_pct_correct=0.775, train/fwd_pct_correct=0.751, train/loss=13.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.309, train/loss_prior=0.439, train/lr=0.000295, train/num_steps=3934, train/recon_cossim=0.658, train/recon_mse=0.439]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 14/150 [12:49<1:53:31, 50.08s/it, test/blurry_pixcorr=0, test/loss=15.8, test/loss_clip_total=1.87, test/loss_prior=0.464, test/num_steps=15, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.507, test/test_fwd_pct_correct=0.673, train/blurry_pixcorr=0, train/bwd_pct_correct=0.78, train/fwd_pct_correct=0.745, train/loss=13.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.293, train/loss_prior=0.432, train/lr=0.000294, train/num_steps=4215, train/recon_cossim=0.664, train/recon_mse=0.432]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 15/150 [13:39<1:52:23, 49.95s/it, test/blurry_pixcorr=0, test/loss=15.9, test/loss_clip_total=2.04, test/loss_prior=0.462, test/num_steps=16, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.487, test/test_fwd_pct_correct=0.583, train/blurry_pixcorr=0, train/bwd_pct_correct=0.77, train/fwd_pct_correct=0.734, train/loss=13.1, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.3, train/loss_prior=0.425, train/lr=0.000293, train/num_steps=4496, train/recon_cossim=0.67, train/recon_mse=0.425]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | 16/150 [14:30<1:51:26, 49.90s/it, test/blurry_pixcorr=0, test/loss=15.3, test/loss_clip_total=1.74, test/loss_prior=0.454, test/num_steps=17, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.58, test/test_fwd_pct_correct=0.693, train/blurry_pixcorr=0, train/bwd_pct_correct=0.764, train/fwd_pct_correct=0.731, train/loss=13.4, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.3, train/loss_prior=0.436, train/lr=0.000292, train/num_steps=4777, train/recon_cossim=0.663, train/recon_mse=0.436]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 17/150 [15:20<1:51:42, 50.39s/it, test/blurry_pixcorr=0, test/loss=16.1, test/loss_clip_total=1.84, test/loss_prior=0.475, test/num_steps=18, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.543, test/test_fwd_pct_correct=0.587, train/blurry_pixcorr=0, train/bwd_pct_correct=0.765, train/fwd_pct_correct=0.735, train/loss=13.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.299, train/loss_prior=0.429, train/lr=0.000291, train/num_steps=5058, train/recon_cossim=0.667, train/recon_mse=0.429]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | 18/150 [16:10<1:50:33, 50.25s/it, test/blurry_pixcorr=0, test/loss=17.1, test/loss_clip_total=1.94, test/loss_prior=0.506, test/num_steps=19, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.557, test/test_fwd_pct_correct=0.557, train/blurry_pixcorr=0, train/bwd_pct_correct=0.766, train/fwd_pct_correct=0.736, train/loss=12.6, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.312, train/loss_prior=0.41, train/lr=0.00029, train/num_steps=5339, train/recon_cossim=0.683, train/recon_mse=0.41]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 19/150 [17:01<1:49:30, 50.15s/it, test/blurry_pixcorr=0, test/loss=16.4, test/loss_clip_total=1.88, test/loss_prior=0.485, test/num_steps=20, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.573, test/test_fwd_pct_correct=0.587, train/blurry_pixcorr=0, train/bwd_pct_correct=0.771, train/fwd_pct_correct=0.732, train/loss=12.8, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.313, train/loss_prior=0.415, train/lr=0.000289, train/num_steps=5620, train/recon_cossim=0.679, train/recon_mse=0.415]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | 20/150 [17:50<1:48:55, 50.27s/it, test/blurry_pixcorr=0, test/loss=16.2, test/loss_clip_total=2.03, test/loss_prior=0.472, test/num_steps=21, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.513, test/test_fwd_pct_correct=0.57, train/blurry_pixcorr=0, train/bwd_pct_correct=0.774, train/fwd_pct_correct=0.742, train/loss=12.7, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.281, train/loss_prior=0.413, train/lr=0.000288, train/num_steps=5901, train/recon_cossim=0.683, train/recon_mse=0.413]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | 21/150 [18:39<1:47:21, 49.93s/it, test/blurry_pixcorr=0, test/loss=14.8, test/loss_clip_total=1.91, test/loss_prior=0.429, test/num_steps=22, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.597, test/test_fwd_pct_correct=0.53, train/blurry_pixcorr=0, train/bwd_pct_correct=0.773, train/fwd_pct_correct=0.737, train/loss=12.4, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.28, train/loss_prior=0.403, train/lr=0.000287, train/num_steps=6182, train/recon_cossim=0.69, train/recon_mse=0.403]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 22/150 [19:29<1:45:53, 49.64s/it, test/blurry_pixcorr=0, test/loss=15.7, test/loss_clip_total=2.09, test/loss_prior=0.453, test/num_steps=23, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.53, test/test_fwd_pct_correct=0.493, train/blurry_pixcorr=0, train/bwd_pct_correct=0.774, train/fwd_pct_correct=0.743, train/loss=12.9, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.289, train/loss_prior=0.419, train/lr=0.000285, train/num_steps=6463, train/recon_cossim=0.676, train/recon_mse=0.419]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 23/150 [20:21<1:45:26, 49.82s/it, test/blurry_pixcorr=0, test/loss=16.1, test/loss_clip_total=1.99, test/loss_prior=0.471, test/num_steps=24, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.54, test/test_fwd_pct_correct=0.5, train/blurry_pixcorr=0, train/bwd_pct_correct=0.775, train/fwd_pct_correct=0.747, train/loss=12.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.284, train/loss_prior=0.406, train/lr=0.000284, train/num_steps=6744, train/recon_cossim=0.686, train/recon_mse=0.406]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | 24/150 [21:11<1:46:25, 50.68s/it, test/blurry_pixcorr=0, test/loss=15.2, test/loss_clip_total=1.89, test/loss_prior=0.443, test/num_steps=25, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.597, test/test_fwd_pct_correct=0.61, train/blurry_pixcorr=0, train/bwd_pct_correct=0.773, train/fwd_pct_correct=0.73, train/loss=12.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.287, train/loss_prior=0.407, train/lr=0.000283, train/num_steps=7025, train/recon_cossim=0.687, train/recon_mse=0.407]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | 25/150 [22:01<1:45:11, 50.49s/it, test/blurry_pixcorr=0, test/loss=15.1, test/loss_clip_total=1.83, test/loss_prior=0.443, test/num_steps=26, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.62, test/test_fwd_pct_correct=0.61, train/blurry_pixcorr=0, train/bwd_pct_correct=0.77, train/fwd_pct_correct=0.737, train/loss=12.3, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.28, train/loss_prior=0.402, train/lr=0.000281, train/num_steps=7306, train/recon_cossim=0.691, train/recon_mse=0.402]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 26/150 [22:51<1:43:46, 50.21s/it, test/blurry_pixcorr=0, test/loss=13.9, test/loss_clip_total=1.91, test/loss_prior=0.399, test/num_steps=27, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.553, test/test_fwd_pct_correct=0.573, train/blurry_pixcorr=0, train/bwd_pct_correct=0.767, train/fwd_pct_correct=0.733, train/loss=12.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.296, train/loss_prior=0.398, train/lr=0.000279, train/num_steps=7587, train/recon_cossim=0.694, train/recon_mse=0.398]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | 27/150 [23:41<1:42:46, 50.14s/it, test/blurry_pixcorr=0, test/loss=16.3, test/loss_clip_total=1.91, test/loss_prior=0.48, test/num_steps=28, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.587, test/test_fwd_pct_correct=0.567, train/blurry_pixcorr=0, train/bwd_pct_correct=0.777, train/fwd_pct_correct=0.733, train/loss=12.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.258, train/loss_prior=0.397, train/lr=0.000278, train/num_steps=7868, train/recon_cossim=0.695, train/recon_mse=0.397]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | 28/150 [24:31<1:42:01, 50.18s/it, test/blurry_pixcorr=0, test/loss=15.5, test/loss_clip_total=1.73, test/loss_prior=0.461, test/num_steps=29, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.633, test/test_fwd_pct_correct=0.677, train/blurry_pixcorr=0, train/bwd_pct_correct=0.777, train/fwd_pct_correct=0.729, train/loss=12.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.293, train/loss_prior=0.396, train/lr=0.000276, train/num_steps=8149, train/recon_cossim=0.696, train/recon_mse=0.396]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 29/150 [25:20<1:40:38, 49.91s/it, test/blurry_pixcorr=0, test/loss=15, test/loss_clip_total=1.75, test/loss_prior=0.441, test/num_steps=30, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.66, test/test_fwd_pct_correct=0.61, train/blurry_pixcorr=0, train/bwd_pct_correct=0.777, train/fwd_pct_correct=0.738, train/loss=11.9, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.274, train/loss_prior=0.386, train/lr=0.000274, train/num_steps=8430, train/recon_cossim=0.704, train/recon_mse=0.386]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 30/150 [26:10<1:39:37, 49.81s/it, test/blurry_pixcorr=0, test/loss=14.8, test/loss_clip_total=2.04, test/loss_prior=0.426, test/num_steps=31, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.597, test/test_fwd_pct_correct=0.477, train/blurry_pixcorr=0, train/bwd_pct_correct=0.786, train/fwd_pct_correct=0.753, train/loss=12, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.276, train/loss_prior=0.392, train/lr=0.000273, train/num_steps=8711, train/recon_cossim=0.7, train/recon_mse=0.392]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | 31/150 [27:00<1:38:46, 49.81s/it, test/blurry_pixcorr=0, test/loss=14.2, test/loss_clip_total=1.86, test/loss_prior=0.411, test/num_steps=32, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.67, test/test_fwd_pct_correct=0.567, train/blurry_pixcorr=0, train/bwd_pct_correct=0.771, train/fwd_pct_correct=0.736, train/loss=12.6, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.274, train/loss_prior=0.411, train/lr=0.000271, train/num_steps=8992, train/recon_cossim=0.686, train/recon_mse=0.411]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | 32/150 [27:52<1:38:06, 49.89s/it, test/blurry_pixcorr=0, test/loss=15.6, test/loss_clip_total=1.87, test/loss_prior=0.459, test/num_steps=33, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.59, test/test_fwd_pct_correct=0.597, train/blurry_pixcorr=0, train/bwd_pct_correct=0.784, train/fwd_pct_correct=0.746, train/loss=12, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.267, train/loss_prior=0.391, train/lr=0.000269, train/num_steps=9273, train/recon_cossim=0.702, train/recon_mse=0.391]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | 33/150 [28:41<1:38:12, 50.36s/it, test/blurry_pixcorr=0, test/loss=13.8, test/loss_clip_total=2.1, test/loss_prior=0.39, test/num_steps=34, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.63, test/test_fwd_pct_correct=0.43, train/blurry_pixcorr=0, train/bwd_pct_correct=0.786, train/fwd_pct_correct=0.749, train/loss=11.8, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.269, train/loss_prior=0.385, train/lr=0.000267, train/num_steps=9554, train/recon_cossim=0.706, train/recon_mse=0.385]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 34/150 [29:32<1:37:08, 50.25s/it, test/blurry_pixcorr=0, test/loss=14.6, test/loss_clip_total=1.8, test/loss_prior=0.426, test/num_steps=35, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.643, test/test_fwd_pct_correct=0.703, train/blurry_pixcorr=0, train/bwd_pct_correct=0.783, train/fwd_pct_correct=0.752, train/loss=11.3, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.28, train/loss_prior=0.368, train/lr=0.000265, train/num_steps=9835, train/recon_cossim=0.719, train/recon_mse=0.368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | 35/150 [30:22<1:36:33, 50.38s/it, test/blurry_pixcorr=0, test/loss=12.4, test/loss_clip_total=1.99, test/loss_prior=0.345, test/num_steps=36, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.59, test/test_fwd_pct_correct=0.56, train/blurry_pixcorr=0, train/bwd_pct_correct=0.791, train/fwd_pct_correct=0.759, train/loss=11.7, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.248, train/loss_prior=0.381, train/lr=0.000263, train/num_steps=10116, train/recon_cossim=0.71, train/recon_mse=0.381]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 36/150 [31:13<1:35:24, 50.22s/it, test/blurry_pixcorr=0, test/loss=15.9, test/loss_clip_total=2, test/loss_prior=0.464, test/num_steps=37, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.613, test/test_fwd_pct_correct=0.557, train/blurry_pixcorr=0, train/bwd_pct_correct=0.779, train/fwd_pct_correct=0.733, train/loss=11.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.265, train/loss_prior=0.375, train/lr=0.000261, train/num_steps=10397, train/recon_cossim=0.715, train/recon_mse=0.375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 37/150 [32:03<1:34:47, 50.33s/it, test/blurry_pixcorr=0, test/loss=16.8, test/loss_clip_total=1.93, test/loss_prior=0.496, test/num_steps=38, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.643, test/test_fwd_pct_correct=0.563, train/blurry_pixcorr=0, train/bwd_pct_correct=0.776, train/fwd_pct_correct=0.737, train/loss=11.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.26, train/loss_prior=0.374, train/lr=0.000258, train/num_steps=10678, train/recon_cossim=0.716, train/recon_mse=0.374]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | 38/150 [32:53<1:33:52, 50.29s/it, test/blurry_pixcorr=0, test/loss=14.8, test/loss_clip_total=2.19, test/loss_prior=0.422, test/num_steps=39, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.543, test/test_fwd_pct_correct=0.447, train/blurry_pixcorr=0, train/bwd_pct_correct=0.778, train/fwd_pct_correct=0.744, train/loss=11.4, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.266, train/loss_prior=0.371, train/lr=0.000256, train/num_steps=10959, train/recon_cossim=0.717, train/recon_mse=0.371]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | 39/150 [33:44<1:32:32, 50.02s/it, test/blurry_pixcorr=0, test/loss=15, test/loss_clip_total=1.96, test/loss_prior=0.436, test/num_steps=40, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.633, test/test_fwd_pct_correct=0.557, train/blurry_pixcorr=0, train/bwd_pct_correct=0.782, train/fwd_pct_correct=0.74, train/loss=11.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.256, train/loss_prior=0.375, train/lr=0.000254, train/num_steps=11240, train/recon_cossim=0.713, train/recon_mse=0.375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | 40/150 [34:34<1:32:30, 50.46s/it, test/blurry_pixcorr=0, test/loss=15.6, test/loss_clip_total=2.01, test/loss_prior=0.453, test/num_steps=41, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.63, test/test_fwd_pct_correct=0.44, train/blurry_pixcorr=0, train/bwd_pct_correct=0.782, train/fwd_pct_correct=0.736, train/loss=11.7, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.253, train/loss_prior=0.381, train/lr=0.000252, train/num_steps=11521, train/recon_cossim=0.71, train/recon_mse=0.381]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 41/150 [35:24<1:31:27, 50.35s/it, test/blurry_pixcorr=0, test/loss=14.2, test/loss_clip_total=2.09, test/loss_prior=0.403, test/num_steps=42, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.57, test/test_fwd_pct_correct=0.54, train/blurry_pixcorr=0, train/bwd_pct_correct=0.782, train/fwd_pct_correct=0.736, train/loss=11.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.263, train/loss_prior=0.365, train/lr=0.000249, train/num_steps=11802, train/recon_cossim=0.723, train/recon_mse=0.365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | 42/150 [36:14<1:30:20, 50.19s/it, test/blurry_pixcorr=0, test/loss=16.6, test/loss_clip_total=2.12, test/loss_prior=0.484, test/num_steps=43, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.58, test/test_fwd_pct_correct=0.517, train/blurry_pixcorr=0, train/bwd_pct_correct=0.778, train/fwd_pct_correct=0.725, train/loss=11.3, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.258, train/loss_prior=0.369, train/lr=0.000247, train/num_steps=12083, train/recon_cossim=0.719, train/recon_mse=0.369]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | 43/150 [37:04<1:29:22, 50.11s/it, test/blurry_pixcorr=0, test/loss=15.7, test/loss_clip_total=2.15, test/loss_prior=0.453, test/num_steps=44, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.61, test/test_fwd_pct_correct=0.47, train/blurry_pixcorr=0, train/bwd_pct_correct=0.777, train/fwd_pct_correct=0.723, train/loss=11.3, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.256, train/loss_prior=0.367, train/lr=0.000244, train/num_steps=12364, train/recon_cossim=0.72, train/recon_mse=0.367]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 44/150 [37:54<1:28:27, 50.07s/it, test/blurry_pixcorr=0, test/loss=14.9, test/loss_clip_total=2.07, test/loss_prior=0.426, test/num_steps=45, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.597, test/test_fwd_pct_correct=0.52, train/blurry_pixcorr=0, train/bwd_pct_correct=0.769, train/fwd_pct_correct=0.726, train/loss=11.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.261, train/loss_prior=0.374, train/lr=0.000242, train/num_steps=12645, train/recon_cossim=0.718, train/recon_mse=0.374]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | 45/150 [38:43<1:27:40, 50.10s/it, test/blurry_pixcorr=0, test/loss=12.9, test/loss_clip_total=2.16, test/loss_prior=0.357, test/num_steps=46, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.573, test/test_fwd_pct_correct=0.443, train/blurry_pixcorr=0, train/bwd_pct_correct=0.764, train/fwd_pct_correct=0.723, train/loss=11.4, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.271, train/loss_prior=0.373, train/lr=0.000239, train/num_steps=12926, train/recon_cossim=0.717, train/recon_mse=0.373]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                | 46/150 [39:34<1:26:14, 49.76s/it, test/blurry_pixcorr=0, test/loss=13.9, test/loss_clip_total=2.12, test/loss_prior=0.393, test/num_steps=47, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.62, test/test_fwd_pct_correct=0.537, train/blurry_pixcorr=0, train/bwd_pct_correct=0.771, train/fwd_pct_correct=0.731, train/loss=11.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.27, train/loss_prior=0.364, train/lr=0.000237, train/num_steps=13207, train/recon_cossim=0.725, train/recon_mse=0.364]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|                                                                                                                                                                                                                                                                                                                                                                                                                                                             | 47/150 [40:28<1:26:33, 50.42s/it, test/blurry_pixcorr=0, test/loss=16.4, test/loss_clip_total=1.96, test/loss_prior=0.48, test/num_steps=48, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.657, test/test_fwd_pct_correct=0.55, train/blurry_pixcorr=0, train/bwd_pct_correct=0.771, train/fwd_pct_correct=0.726, train/loss=11, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.261, train/loss_prior=0.356, train/lr=0.000234, train/num_steps=13488, train/recon_cossim=0.731, train/recon_mse=0.356]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 48/150 [41:19<1:27:07, 51.25s/it, test/blurry_pixcorr=0, test/loss=15.1, test/loss_clip_total=1.95, test/loss_prior=0.44, test/num_steps=49, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.723, test/test_fwd_pct_correct=0.577, train/blurry_pixcorr=0, train/bwd_pct_correct=0.776, train/fwd_pct_correct=0.736, train/loss=10.9, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.247, train/loss_prior=0.356, train/lr=0.000231, train/num_steps=13769, train/recon_cossim=0.731, train/recon_mse=0.356]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|                                                                                                                                                                                                                                                                                                                                                                                                                                                  | 49/150 [42:09<1:26:03, 51.13s/it, test/blurry_pixcorr=0, test/loss=13.3, test/loss_clip_total=1.72, test/loss_prior=0.385, test/num_steps=50, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.67, test/test_fwd_pct_correct=0.65, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=10.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00796, train/loss_prior=0.349, train/lr=0.000229, train/num_steps=14050, train/recon_cossim=0.737, train/recon_mse=0.349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|                                                                                                                                                                                                                                                                                                                                                                                                                                            | 50/150 [42:59<1:25:05, 51.05s/it, test/blurry_pixcorr=0, test/loss=14.6, test/loss_clip_total=1.58, test/loss_prior=0.435, test/num_steps=51, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.683, test/test_fwd_pct_correct=0.667, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=10.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00688, train/loss_prior=0.351, train/lr=0.000226, train/num_steps=14331, train/recon_cossim=0.738, train/recon_mse=0.351]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|                                                                                                                                                                                                                                                                                                                                                                                                                                        | 51/150 [43:49<1:23:17, 50.48s/it, test/blurry_pixcorr=0, test/loss=15.1, test/loss_clip_total=1.57, test/loss_prior=0.449, test/num_steps=52, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.677, test/test_fwd_pct_correct=0.653, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=10.4, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00646, train/loss_prior=0.346, train/lr=0.000223, train/num_steps=14612, train/recon_cossim=0.742, train/recon_mse=0.346]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|                                                                                                                                                                                                                                                                                                                                                                                                                                    | 52/150 [44:38<1:22:10, 50.31s/it, test/blurry_pixcorr=0, test/loss=16.5, test/loss_clip_total=1.46, test/loss_prior=0.503, test/num_steps=53, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.653, test/test_fwd_pct_correct=0.687, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.999, train/loss=10.1, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00332, train/loss_prior=0.336, train/lr=0.00022, train/num_steps=14893, train/recon_cossim=0.748, train/recon_mse=0.336]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|                                                                                                                                                                                                                                                                                                                                                                                                                                 | 53/150 [45:29<1:21:10, 50.21s/it, test/blurry_pixcorr=0, test/loss=13.5, test/loss_clip_total=1.5, test/loss_prior=0.401, test/num_steps=54, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.66, test/test_fwd_pct_correct=0.71, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.995, train/loss=9.93, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00942, train/loss_prior=0.331, train/lr=0.000218, train/num_steps=15174, train/recon_cossim=0.754, train/recon_mse=0.331]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|                                                                                                                                                                                                                                                                                                                                                                                                                            | 54/150 [46:19<1:20:37, 50.40s/it, test/blurry_pixcorr=0, test/loss=13.4, test/loss_clip_total=1.53, test/loss_prior=0.396, test/num_steps=55, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.617, test/test_fwd_pct_correct=0.73, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.997, train/loss=10.5, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00618, train/loss_prior=0.349, train/lr=0.000215, train/num_steps=15455, train/recon_cossim=0.741, train/recon_mse=0.349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                                                                                                                                                                                                                                                                                                                                                                                          | 55/150 [47:09<1:19:11, 50.02s/it, test/blurry_pixcorr=0, test/loss=15, test/loss_clip_total=1.39, test/loss_prior=0.454, test/num_steps=56, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.693, test/test_fwd_pct_correct=0.73, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=9.91, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00668, train/loss_prior=0.33, train/lr=0.000212, train/num_steps=15736, train/recon_cossim=0.753, train/recon_mse=0.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|                                                                                                                                                                                                                                                                                                                                                                                                                   | 56/150 [47:58<1:18:06, 49.85s/it, test/blurry_pixcorr=0, test/loss=14.3, test/loss_clip_total=1.47, test/loss_prior=0.427, test/num_steps=57, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.667, test/test_fwd_pct_correct=0.72, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.998, train/loss=9.87, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00714, train/loss_prior=0.329, train/lr=0.000209, train/num_steps=16017, train/recon_cossim=0.757, train/recon_mse=0.329]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|                                                                                                                                                                                                                                                                                                                                                                                                                | 57/150 [48:58<1:17:16, 49.86s/it, test/blurry_pixcorr=0, test/loss=15.5, test/loss_clip_total=1.45, test/loss_prior=0.467, test/num_steps=58, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.703, test/test_fwd_pct_correct=0.753, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.996, train/loss=9.82, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0129, train/loss_prior=0.327, train/lr=0.000206, train/num_steps=16298, train/recon_cossim=0.76, train/recon_mse=0.327]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|                                                                                                                                                                                                                                                                                                                                                                                                           | 58/150 [49:47<1:20:46, 52.67s/it, test/blurry_pixcorr=0, test/loss=14.6, test/loss_clip_total=1.34, test/loss_prior=0.443, test/num_steps=59, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.733, test/test_fwd_pct_correct=0.74, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=9.71, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00442, train/loss_prior=0.324, train/lr=0.000203, train/num_steps=16579, train/recon_cossim=0.761, train/recon_mse=0.324]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|                                                                                                                                                                                                                                                                                                                                                                                                       | 59/150 [50:37<1:18:38, 51.86s/it, test/blurry_pixcorr=0, test/loss=13.7, test/loss_clip_total=1.29, test/loss_prior=0.415, test/num_steps=60, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.723, test/test_fwd_pct_correct=0.747, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=9.67, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00653, train/loss_prior=0.322, train/lr=0.0002, train/num_steps=16860, train/recon_cossim=0.761, train/recon_mse=0.322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|                                                                                                                                                                                                                                                                                                                                                                                                   | 60/150 [51:27<1:16:55, 51.29s/it, test/blurry_pixcorr=0, test/loss=15.9, test/loss_clip_total=1.27, test/loss_prior=0.487, test/num_steps=61, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.71, test/test_fwd_pct_correct=0.78, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=9.85, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00683, train/loss_prior=0.328, train/lr=0.000197, train/num_steps=17141, train/recon_cossim=0.757, train/recon_mse=0.328]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|                                                                                                                                                                                                                                                                                                                                                                                             | 61/150 [52:17<1:15:28, 50.88s/it, test/blurry_pixcorr=0, test/loss=14.6, test/loss_clip_total=1.29, test/loss_prior=0.444, test/num_steps=62, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.733, test/test_fwd_pct_correct=0.703, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.999, train/loss=9.67, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00229, train/loss_prior=0.322, train/lr=0.000194, train/num_steps=17422, train/recon_cossim=0.763, train/recon_mse=0.322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|                                                                                                                                                                                                                                                                                                                                                                                         | 62/150 [53:07<1:14:03, 50.49s/it, test/blurry_pixcorr=0, test/loss=15.4, test/loss_clip_total=1.22, test/loss_prior=0.474, test/num_steps=63, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.77, test/test_fwd_pct_correct=0.753, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.999, train/loss=9.54, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00253, train/loss_prior=0.318, train/lr=0.000191, train/num_steps=17703, train/recon_cossim=0.766, train/recon_mse=0.318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|                                                                                                                                                                                                                                                                                                                                                                                      | 63/150 [53:56<1:12:56, 50.30s/it, test/blurry_pixcorr=0, test/loss=13.2, test/loss_clip_total=1.17, test/loss_prior=0.401, test/num_steps=64, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.76, test/test_fwd_pct_correct=0.787, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=9.4, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00331, train/loss_prior=0.313, train/lr=0.000188, train/num_steps=17984, train/recon_cossim=0.77, train/recon_mse=0.313]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|                                                                                                                                                                                                                                                                                                                                                                                   | 64/150 [54:47<1:11:50, 50.12s/it, test/blurry_pixcorr=0, test/loss=13.9, test/loss_clip_total=1.18, test/loss_prior=0.424, test/num_steps=65, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.773, test/test_fwd_pct_correct=0.72, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=9.3, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00525, train/loss_prior=0.31, train/lr=0.000185, train/num_steps=18265, train/recon_cossim=0.773, train/recon_mse=0.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|                                                                                                                                                                                                                                                                                                                                                                              | 65/150 [55:37<1:11:18, 50.34s/it, test/blurry_pixcorr=0, test/loss=15, test/loss_clip_total=2.01, test/loss_prior=0.433, test/num_steps=66, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.55, test/test_fwd_pct_correct=0.487, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.996, train/loss=8.93, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00871, train/loss_prior=0.297, train/lr=0.000182, train/num_steps=18546, train/recon_cossim=0.783, train/recon_mse=0.297]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|                                                                                                                                                                                                                                                                                                                                                                         | 66/150 [56:25<1:09:59, 50.00s/it, test/blurry_pixcorr=0, test/loss=14.4, test/loss_clip_total=1.44, test/loss_prior=0.43, test/num_steps=67, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.67, test/test_fwd_pct_correct=0.667, train/blurry_pixcorr=0, train/bwd_pct_correct=0.994, train/fwd_pct_correct=0.994, train/loss=8.98, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00947, train/loss_prior=0.299, train/lr=0.000179, train/num_steps=18827, train/recon_cossim=0.781, train/recon_mse=0.299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|                                                                                                                                                                                                                                                                                                                                                                   | 67/150 [57:17<1:08:44, 49.70s/it, test/blurry_pixcorr=0, test/loss=14.2, test/loss_clip_total=1.35, test/loss_prior=0.428, test/num_steps=68, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.707, test/test_fwd_pct_correct=0.677, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.999, train/loss=9.49, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00201, train/loss_prior=0.316, train/lr=0.000175, train/num_steps=19108, train/recon_cossim=0.768, train/recon_mse=0.316]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|                                                                                                                                                                                                                                                                                                                                                                | 68/150 [58:07<1:08:54, 50.42s/it, test/blurry_pixcorr=0, test/loss=14.6, test/loss_clip_total=1.43, test/loss_prior=0.439, test/num_steps=69, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.63, test/test_fwd_pct_correct=0.713, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.998, train/loss=9.37, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00596, train/loss_prior=0.312, train/lr=0.000172, train/num_steps=19389, train/recon_cossim=0.771, train/recon_mse=0.312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|                                                                                                                                                                                                                                                                                                                                                           | 69/150 [58:58<1:07:59, 50.37s/it, test/blurry_pixcorr=0, test/loss=11.8, test/loss_clip_total=1.48, test/loss_prior=0.343, test/num_steps=70, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.62, test/test_fwd_pct_correct=0.693, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.997, train/loss=8.88, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00739, train/loss_prior=0.296, train/lr=0.000169, train/num_steps=19670, train/recon_cossim=0.785, train/recon_mse=0.296]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|                                                                                                                                                                                                                                                                                                                                                        | 70/150 [59:47<1:06:58, 50.23s/it, test/blurry_pixcorr=0, test/loss=14.4, test/loss_clip_total=1.26, test/loss_prior=0.439, test/num_steps=71, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.71, test/test_fwd_pct_correct=0.723, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=8.45, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0034, train/loss_prior=0.282, train/lr=0.000166, train/num_steps=2e+4, train/recon_cossim=0.793, train/recon_mse=0.282]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|                                                                                                                                                                                                                                                                                                                                                 | 71/150 [1:00:37<1:05:52, 50.03s/it, test/blurry_pixcorr=0, test/loss=13.9, test/loss_clip_total=1.29, test/loss_prior=0.422, test/num_steps=72, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.707, test/test_fwd_pct_correct=0.717, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.995, train/loss=8.59, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00951, train/loss_prior=0.286, train/lr=0.000163, train/num_steps=20232, train/recon_cossim=0.792, train/recon_mse=0.286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|                                                                                                                                                                                                                                                                                                                                             | 72/150 [1:01:27<1:04:54, 49.93s/it, test/blurry_pixcorr=0, test/loss=13.7, test/loss_clip_total=1.49, test/loss_prior=0.406, test/num_steps=73, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.663, test/test_fwd_pct_correct=0.677, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=8.66, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00638, train/loss_prior=0.289, train/lr=0.00016, train/num_steps=20513, train/recon_cossim=0.789, train/recon_mse=0.289]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|                                                                                                                                                                                                                                                                                                                                         | 73/150 [1:02:17<1:04:03, 49.92s/it, test/blurry_pixcorr=0, test/loss=15.8, test/loss_clip_total=1.41, test/loss_prior=0.479, test/num_steps=74, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.687, test/test_fwd_pct_correct=0.697, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=8.52, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00565, train/loss_prior=0.284, train/lr=0.000157, train/num_steps=20794, train/recon_cossim=0.793, train/recon_mse=0.284]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|                                                                                                                                                                                                                                                                                                                                    | 74/150 [1:03:08<1:03:36, 50.22s/it, test/blurry_pixcorr=0, test/loss=15.8, test/loss_clip_total=1.24, test/loss_prior=0.485, test/num_steps=75, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.737, test/test_fwd_pct_correct=0.733, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.999, train/loss=8.44, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00152, train/loss_prior=0.281, train/lr=0.000153, train/num_steps=21075, train/recon_cossim=0.794, train/recon_mse=0.281]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                                                                                                                                                                                                                                                                                                                                  | 75/150 [1:03:56<1:02:34, 50.06s/it, test/blurry_pixcorr=0, test/loss=13.3, test/loss_clip_total=1.18, test/loss_prior=0.405, test/num_steps=76, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.747, test/test_fwd_pct_correct=0.76, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.997, train/loss=8.71, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00574, train/loss_prior=0.29, train/lr=0.00015, train/num_steps=21356, train/recon_cossim=0.788, train/recon_mse=0.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|                                                                                                                                                                                                                                                                                                                            | 76/150 [1:04:45<1:01:21, 49.75s/it, test/blurry_pixcorr=0, test/loss=15.5, test/loss_clip_total=1.14, test/loss_prior=0.48, test/num_steps=77, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.767, test/test_fwd_pct_correct=0.747, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=8.31, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00471, train/loss_prior=0.277, train/lr=0.000147, train/num_steps=21637, train/recon_cossim=0.798, train/recon_mse=0.277]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|                                                                                                                                                                                                                                                                                                                        | 77/150 [1:05:34<1:00:13, 49.50s/it, test/blurry_pixcorr=0, test/loss=14.5, test/loss_clip_total=1.18, test/loss_prior=0.444, test/num_steps=78, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.763, test/test_fwd_pct_correct=0.737, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=8.23, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00367, train/loss_prior=0.274, train/lr=0.000144, train/num_steps=21918, train/recon_cossim=0.799, train/recon_mse=0.274]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|                                                                                                                                                                                                                                                                                                                     | 78/150 [1:06:23<59:11, 49.32s/it, test/blurry_pixcorr=0, test/loss=13.9, test/loss_clip_total=1.25, test/loss_prior=0.42, test/num_steps=79, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.753, test/test_fwd_pct_correct=0.72, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=8.01, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00924, train/loss_prior=0.267, train/lr=0.000141, train/num_steps=22199, train/recon_cossim=0.806, train/recon_mse=0.267]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|                                                                                                                                                                                                                                                                                                                  | 79/150 [1:07:12<58:13, 49.21s/it, test/blurry_pixcorr=0, test/loss=14.2, test/loss_clip_total=1.27, test/loss_prior=0.43, test/num_steps=80, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.767, test/test_fwd_pct_correct=0.69, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.998, train/loss=8.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00261, train/loss_prior=0.273, train/lr=0.000137, train/num_steps=22480, train/recon_cossim=0.8, train/recon_mse=0.273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|                                                                                                                                                                                                                                                                                                             | 80/150 [1:08:02<57:29, 49.28s/it, test/blurry_pixcorr=0, test/loss=12.5, test/loss_clip_total=1.17, test/loss_prior=0.379, test/num_steps=81, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.78, test/test_fwd_pct_correct=0.717, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=8.09, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00515, train/loss_prior=0.27, train/lr=0.000134, train/num_steps=22761, train/recon_cossim=0.803, train/recon_mse=0.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|                                                                                                                                                                                                                                                                                                       | 81/150 [1:08:51<56:38, 49.25s/it, test/blurry_pixcorr=0, test/loss=13.8, test/loss_clip_total=1.12, test/loss_prior=0.422, test/num_steps=82, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.773, test/test_fwd_pct_correct=0.727, train/blurry_pixcorr=0, train/bwd_pct_correct=0.994, train/fwd_pct_correct=0.994, train/loss=8.15, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00902, train/loss_prior=0.271, train/lr=0.000131, train/num_steps=23042, train/recon_cossim=0.802, train/recon_mse=0.271]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|                                                                                                                                                                                                                                                                                                    | 82/150 [1:09:40<55:49, 49.26s/it, test/blurry_pixcorr=0, test/loss=12.6, test/loss_clip_total=1.14, test/loss_prior=0.384, test/num_steps=83, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.747, test/test_fwd_pct_correct=0.76, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=7.75, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00478, train/loss_prior=0.258, train/lr=0.000128, train/num_steps=23323, train/recon_cossim=0.811, train/recon_mse=0.258]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|                                                                                                                                                                                                                                                                                               | 83/150 [1:10:29<54:56, 49.21s/it, test/blurry_pixcorr=0, test/loss=15.4, test/loss_clip_total=1.12, test/loss_prior=0.477, test/num_steps=84, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.767, test/test_fwd_pct_correct=0.733, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=7.74, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00269, train/loss_prior=0.258, train/lr=0.000125, train/num_steps=23604, train/recon_cossim=0.811, train/recon_mse=0.258]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|                                                                                                                                                                                                                                                                                           | 84/150 [1:11:18<54:09, 49.23s/it, test/blurry_pixcorr=0, test/loss=14.7, test/loss_clip_total=1.11, test/loss_prior=0.454, test/num_steps=85, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.75, test/test_fwd_pct_correct=0.76, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=7.65, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00641, train/loss_prior=0.255, train/lr=0.000122, train/num_steps=23885, train/recon_cossim=0.813, train/recon_mse=0.255]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|                                                                                                                                                                                                                                                                                      | 85/150 [1:12:07<53:18, 49.20s/it, test/blurry_pixcorr=0, test/loss=14.7, test/loss_clip_total=1.14, test/loss_prior=0.451, test/num_steps=86, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.747, test/test_fwd_pct_correct=0.723, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=7.69, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00416, train/loss_prior=0.256, train/lr=0.000119, train/num_steps=24166, train/recon_cossim=0.812, train/recon_mse=0.256]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|                                                                                                                                                                                                                                                                                   | 86/150 [1:12:57<52:29, 49.21s/it, test/blurry_pixcorr=0, test/loss=13.8, test/loss_clip_total=1.08, test/loss_prior=0.422, test/num_steps=87, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.777, test/test_fwd_pct_correct=0.757, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=7.8, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00591, train/loss_prior=0.26, train/lr=0.000115, train/num_steps=24447, train/recon_cossim=0.808, train/recon_mse=0.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|                                                                                                                                                                                                                                                                              | 87/150 [1:13:47<51:49, 49.35s/it, test/blurry_pixcorr=0, test/loss=15.8, test/loss_clip_total=1.12, test/loss_prior=0.491, test/num_steps=88, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.743, test/test_fwd_pct_correct=0.76, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=7.69, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00464, train/loss_prior=0.256, train/lr=0.000112, train/num_steps=24728, train/recon_cossim=0.812, train/recon_mse=0.256]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|                                                                                                                                                                                                                                                                          | 88/150 [1:14:36<50:43, 49.10s/it, test/blurry_pixcorr=0, test/loss=13.1, test/loss_clip_total=1.09, test/loss_prior=0.399, test/num_steps=89, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.73, test/test_fwd_pct_correct=0.81, train/blurry_pixcorr=0, train/bwd_pct_correct=0.994, train/fwd_pct_correct=0.995, train/loss=7.62, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00915, train/loss_prior=0.254, train/lr=0.000109, train/num_steps=25009, train/recon_cossim=0.814, train/recon_mse=0.254]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|                                                                                                                                                                                                                                                                      | 89/150 [1:15:27<50:07, 49.31s/it, test/blurry_pixcorr=0, test/loss=15.2, test/loss_clip_total=1.1, test/loss_prior=0.468, test/num_steps=90, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.747, test/test_fwd_pct_correct=0.817, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.995, train/loss=7.14, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00887, train/loss_prior=0.238, train/lr=0.000106, train/num_steps=25290, train/recon_cossim=0.825, train/recon_mse=0.238]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|                                                                                                                                                                                                                                                                  | 90/150 [1:16:16<49:45, 49.76s/it, test/blurry_pixcorr=0, test/loss=15.1, test/loss_clip_total=1.1, test/loss_prior=0.468, test/num_steps=91, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.713, test/test_fwd_pct_correct=0.81, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.999, train/loss=7.82, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00227, train/loss_prior=0.261, train/lr=0.000103, train/num_steps=25571, train/recon_cossim=0.808, train/recon_mse=0.261]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|                                                                                                                                                                                                                                                              | 91/150 [1:17:05<48:47, 49.63s/it, test/blurry_pixcorr=0, test/loss=14.5, test/loss_clip_total=1.19, test/loss_prior=0.445, test/num_steps=92, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.707, test/test_fwd_pct_correct=0.78, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.997, train/loss=7.43, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00729, train/loss_prior=0.248, train/lr=0.0001, train/num_steps=25852, train/recon_cossim=0.818, train/recon_mse=0.248]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|                                                                                                                                                                                                                                                         | 92/150 [1:17:54<47:47, 49.43s/it, test/blurry_pixcorr=0, test/loss=16.6, test/loss_clip_total=1.11, test/loss_prior=0.516, test/num_steps=93, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.74, test/test_fwd_pct_correct=0.803, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.82, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00571, train/loss_prior=0.227, train/lr=9.72e-5, train/num_steps=26133, train/recon_cossim=0.833, train/recon_mse=0.227]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|                                                                                                                                                                                                                                                     | 93/150 [1:18:44<47:04, 49.55s/it, test/blurry_pixcorr=0, test/loss=15, test/loss_clip_total=1.05, test/loss_prior=0.466, test/num_steps=94, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.747, test/test_fwd_pct_correct=0.787, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=7.62, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00458, train/loss_prior=0.254, train/lr=9.42e-5, train/num_steps=26414, train/recon_cossim=0.813, train/recon_mse=0.254]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|                                                                                                                                                                                                                                                | 94/150 [1:19:33<46:10, 49.48s/it, test/blurry_pixcorr=0, test/loss=14.7, test/loss_clip_total=0.985, test/loss_prior=0.456, test/num_steps=95, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.807, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.99, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00398, train/loss_prior=0.233, train/lr=9.13e-5, train/num_steps=26695, train/recon_cossim=0.828, train/recon_mse=0.233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|                                                                                                                                                                                                                                              | 95/150 [1:20:22<45:07, 49.22s/it, test/blurry_pixcorr=0, test/loss=13, test/loss_clip_total=1.03, test/loss_prior=0.398, test/num_steps=96, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.73, test/test_fwd_pct_correct=0.8, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=7.41, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00433, train/loss_prior=0.247, train/lr=8.84e-5, train/num_steps=26976, train/recon_cossim=0.817, train/recon_mse=0.247]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|                                                                                                                                                                                                                                       | 96/150 [1:21:11<44:22, 49.30s/it, test/blurry_pixcorr=0, test/loss=14.1, test/loss_clip_total=0.986, test/loss_prior=0.437, test/num_steps=97, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.75, test/test_fwd_pct_correct=0.817, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.93, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00348, train/loss_prior=0.231, train/lr=8.55e-5, train/num_steps=27257, train/recon_cossim=0.829, train/recon_mse=0.231]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|                                                                                                                                                                                                                                      | 97/150 [1:22:02<43:26, 49.18s/it, test/blurry_pixcorr=0, test/loss=9.84, test/loss_clip_total=0.96, test/loss_prior=0.296, test/num_steps=98, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.78, test/test_fwd_pct_correct=0.813, train/blurry_pixcorr=0, train/bwd_pct_correct=1, train/fwd_pct_correct=1, train/loss=7.17, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00131, train/loss_prior=0.239, train/lr=8.26e-5, train/num_steps=27538, train/recon_cossim=0.823, train/recon_mse=0.239]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|                                                                                                                                                                                                                                | 98/150 [1:22:51<42:55, 49.54s/it, test/blurry_pixcorr=0, test/loss=14.9, test/loss_clip_total=0.953, test/loss_prior=0.464, test/num_steps=99, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.783, test/test_fwd_pct_correct=0.82, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=7.21, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0027, train/loss_prior=0.24, train/lr=7.98e-5, train/num_steps=27819, train/recon_cossim=0.822, train/recon_mse=0.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|                                                                                                                                                                                                                            | 99/150 [1:23:42<42:16, 49.73s/it, test/blurry_pixcorr=0, test/loss=13.3, test/loss_clip_total=0.958, test/loss_prior=0.412, test/num_steps=100, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.78, test/test_fwd_pct_correct=0.82, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.7, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0058, train/loss_prior=0.223, train/lr=7.7e-5, train/num_steps=28100, train/recon_cossim=0.835, train/recon_mse=0.223]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|                                                                                                                                                                                                                      | 100/150 [1:24:33<41:30, 49.82s/it, test/blurry_pixcorr=0, test/loss=14, test/loss_clip_total=0.962, test/loss_prior=0.435, test/num_steps=101, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.78, test/test_fwd_pct_correct=0.817, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.82, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00341, train/loss_prior=0.227, train/lr=7.42e-5, train/num_steps=28381, train/recon_cossim=0.831, train/recon_mse=0.227]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|                                                                                                                                                                                                                 | 101/150 [1:25:23<41:03, 50.27s/it, test/blurry_pixcorr=0, test/loss=14.2, test/loss_clip_total=0.958, test/loss_prior=0.443, test/num_steps=102, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.773, test/test_fwd_pct_correct=0.793, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.57, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0033, train/loss_prior=0.219, train/lr=7.15e-5, train/num_steps=28662, train/recon_cossim=0.837, train/recon_mse=0.219]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|                                                                                                                                                                                                             | 102/150 [1:26:13<40:07, 50.16s/it, test/blurry_pixcorr=0, test/loss=15.1, test/loss_clip_total=0.95, test/loss_prior=0.471, test/num_steps=103, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.79, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.84, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00334, train/loss_prior=0.228, train/lr=6.88e-5, train/num_steps=28943, train/recon_cossim=0.831, train/recon_mse=0.228]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|                                                                                                                                                                                                         | 103/150 [1:27:03<39:17, 50.17s/it, test/blurry_pixcorr=0, test/loss=14.6, test/loss_clip_total=1.04, test/loss_prior=0.452, test/num_steps=104, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.753, test/test_fwd_pct_correct=0.78, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.999, train/loss=6.53, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00312, train/loss_prior=0.218, train/lr=6.62e-5, train/num_steps=29224, train/recon_cossim=0.838, train/recon_mse=0.218]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|                                                                                                                                                                                                     | 104/150 [1:27:53<38:27, 50.16s/it, test/blurry_pixcorr=0, test/loss=14.5, test/loss_clip_total=0.953, test/loss_prior=0.451, test/num_steps=105, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.8, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.85, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00324, train/loss_prior=0.228, train/lr=6.35e-5, train/num_steps=29505, train/recon_cossim=0.83, train/recon_mse=0.228]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|                                                                                                                                                                                                 | 105/150 [1:28:43<37:37, 50.16s/it, test/blurry_pixcorr=0, test/loss=13.5, test/loss_clip_total=0.931, test/loss_prior=0.418, test/num_steps=106, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.797, test/test_fwd_pct_correct=0.793, train/blurry_pixcorr=0, train/bwd_pct_correct=0.992, train/fwd_pct_correct=0.992, train/loss=6.68, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0119, train/loss_prior=0.222, train/lr=6.1e-5, train/num_steps=29786, train/recon_cossim=0.835, train/recon_mse=0.222]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|                                                                                                                                                                                            | 106/150 [1:29:33<36:38, 49.97s/it, test/blurry_pixcorr=0, test/loss=12.4, test/loss_clip_total=0.914, test/loss_prior=0.382, test/num_steps=107, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.803, test/test_fwd_pct_correct=0.783, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.995, train/loss=6.75, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00703, train/loss_prior=0.225, train/lr=5.84e-5, train/num_steps=30067, train/recon_cossim=0.832, train/recon_mse=0.225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|                                                                                                                                                                                        | 107/150 [1:30:24<35:56, 50.14s/it, test/blurry_pixcorr=0, test/loss=12.9, test/loss_clip_total=0.897, test/loss_prior=0.399, test/num_steps=108, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.813, test/test_fwd_pct_correct=0.793, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.77, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0033, train/loss_prior=0.226, train/lr=5.59e-5, train/num_steps=30348, train/recon_cossim=0.832, train/recon_mse=0.226]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|                                                                                                                                                                                    | 108/150 [1:31:14<35:16, 50.40s/it, test/blurry_pixcorr=0, test/loss=13.4, test/loss_clip_total=0.957, test/loss_prior=0.416, test/num_steps=109, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.77, test/test_fwd_pct_correct=0.79, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.61, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00468, train/loss_prior=0.22, train/lr=5.35e-5, train/num_steps=30629, train/recon_cossim=0.835, train/recon_mse=0.22]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|                                                                                                                                                                                | 109/150 [1:32:03<34:14, 50.10s/it, test/blurry_pixcorr=0, test/loss=12.9, test/loss_clip_total=0.93, test/loss_prior=0.399, test/num_steps=110, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.797, test/test_fwd_pct_correct=0.78, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=6.87, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00583, train/loss_prior=0.229, train/lr=5.1e-5, train/num_steps=30910, train/recon_cossim=0.829, train/recon_mse=0.229]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|                                                                                                                                                                           | 110/150 [1:32:53<33:21, 50.04s/it, test/blurry_pixcorr=0, test/loss=14.4, test/loss_clip_total=0.993, test/loss_prior=0.447, test/num_steps=111, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.757, test/test_fwd_pct_correct=0.753, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.67, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00351, train/loss_prior=0.222, train/lr=4.87e-5, train/num_steps=31191, train/recon_cossim=0.833, train/recon_mse=0.222]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|                                                                                                                                                                       | 111/150 [1:33:43<32:29, 49.98s/it, test/blurry_pixcorr=0, test/loss=15.5, test/loss_clip_total=0.952, test/loss_prior=0.484, test/num_steps=112, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.777, test/test_fwd_pct_correct=0.76, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.44, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00324, train/loss_prior=0.215, train/lr=4.64e-5, train/num_steps=31472, train/recon_cossim=0.84, train/recon_mse=0.215]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|                                                                                                                                                                   | 112/150 [1:34:33<31:39, 50.00s/it, test/blurry_pixcorr=0, test/loss=12, test/loss_clip_total=1.09, test/loss_prior=0.363, test/num_steps=113, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.727, test/test_fwd_pct_correct=0.723, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.52, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00503, train/loss_prior=0.217, train/lr=4.41e-5, train/num_steps=31753, train/recon_cossim=0.837, train/recon_mse=0.217]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|                                                                                                                                                              | 113/150 [1:35:23<30:46, 49.91s/it, test/blurry_pixcorr=0, test/loss=13.6, test/loss_clip_total=0.958, test/loss_prior=0.42, test/num_steps=114, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.747, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.12, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00463, train/loss_prior=0.204, train/lr=4.18e-5, train/num_steps=32034, train/recon_cossim=0.847, train/recon_mse=0.204]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|                                                                                                                                                         | 114/150 [1:36:12<29:49, 49.71s/it, test/blurry_pixcorr=0, test/loss=14.8, test/loss_clip_total=0.922, test/loss_prior=0.464, test/num_steps=115, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.793, test/test_fwd_pct_correct=0.763, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.51, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00392, train/loss_prior=0.217, train/lr=3.97e-5, train/num_steps=32315, train/recon_cossim=0.838, train/recon_mse=0.217]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|                                                                                                                                                      | 115/150 [1:37:01<28:53, 49.52s/it, test/blurry_pixcorr=0, test/loss=15, test/loss_clip_total=0.911, test/loss_prior=0.471, test/num_steps=116, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.8, test/test_fwd_pct_correct=0.76, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.997, train/loss=6.45, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00514, train/loss_prior=0.215, train/lr=3.75e-5, train/num_steps=32596, train/recon_cossim=0.839, train/recon_mse=0.215]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|                                                                                                                                                  | 116/150 [1:37:51<28:03, 49.51s/it, test/blurry_pixcorr=0, test/loss=14, test/loss_clip_total=0.907, test/loss_prior=0.436, test/num_steps=117, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.81, test/test_fwd_pct_correct=0.767, train/blurry_pixcorr=0, train/bwd_pct_correct=0.993, train/fwd_pct_correct=0.993, train/loss=6.46, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00953, train/loss_prior=0.215, train/lr=3.55e-5, train/num_steps=32877, train/recon_cossim=0.839, train/recon_mse=0.215]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|                                                                                                                                             | 117/150 [1:38:40<27:15, 49.57s/it, test/blurry_pixcorr=0, test/loss=16.5, test/loss_clip_total=0.889, test/loss_prior=0.521, test/num_steps=118, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.81, test/test_fwd_pct_correct=0.777, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.61, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00331, train/loss_prior=0.22, train/lr=3.34e-5, train/num_steps=33158, train/recon_cossim=0.835, train/recon_mse=0.22]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|                                                                                                                                          | 118/150 [1:39:30<26:24, 49.51s/it, test/blurry_pixcorr=0, test/loss=16, test/loss_clip_total=0.955, test/loss_prior=0.501, test/num_steps=119, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.78, test/test_fwd_pct_correct=0.75, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.4, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00345, train/loss_prior=0.213, train/lr=3.14e-5, train/num_steps=33439, train/recon_cossim=0.84, train/recon_mse=0.213]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|                                                                                                                                     | 119/150 [1:40:20<25:38, 49.61s/it, test/blurry_pixcorr=0, test/loss=13.7, test/loss_clip_total=0.95, test/loss_prior=0.424, test/num_steps=120, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.78, test/test_fwd_pct_correct=0.743, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.42, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00457, train/loss_prior=0.214, train/lr=2.95e-5, train/num_steps=33720, train/recon_cossim=0.839, train/recon_mse=0.214]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|                                                                                                                                | 120/150 [1:41:12<24:58, 49.94s/it, test/blurry_pixcorr=0, test/loss=14.6, test/loss_clip_total=0.88, test/loss_prior=0.459, test/num_steps=121, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.797, test/test_fwd_pct_correct=0.763, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.28, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00465, train/loss_prior=0.209, train/lr=2.77e-5, train/num_steps=34001, train/recon_cossim=0.843, train/recon_mse=0.209]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|                                                                                                                            | 121/150 [1:42:01<24:22, 50.42s/it, test/blurry_pixcorr=0, test/loss=13.9, test/loss_clip_total=0.885, test/loss_prior=0.433, test/num_steps=122, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.79, test/test_fwd_pct_correct=0.773, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.22, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00327, train/loss_prior=0.207, train/lr=2.58e-5, train/num_steps=34282, train/recon_cossim=0.844, train/recon_mse=0.207]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|                                                                                                                       | 122/150 [1:42:51<23:21, 50.07s/it, test/blurry_pixcorr=0, test/loss=13.5, test/loss_clip_total=0.901, test/loss_prior=0.419, test/num_steps=123, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.783, test/test_fwd_pct_correct=0.76, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=5.88, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00325, train/loss_prior=0.196, train/lr=2.41e-5, train/num_steps=34563, train/recon_cossim=0.852, train/recon_mse=0.196]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|                                                                                                                   | 123/150 [1:43:41<22:31, 50.04s/it, test/blurry_pixcorr=0, test/loss=14.5, test/loss_clip_total=0.906, test/loss_prior=0.454, test/num_steps=124, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.79, test/test_fwd_pct_correct=0.763, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.11, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00388, train/loss_prior=0.203, train/lr=2.24e-5, train/num_steps=34844, train/recon_cossim=0.847, train/recon_mse=0.203]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|                                                                                                               | 124/150 [1:44:31<21:38, 49.96s/it, test/blurry_pixcorr=0, test/loss=15.6, test/loss_clip_total=0.879, test/loss_prior=0.49, test/num_steps=125, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.807, test/test_fwd_pct_correct=0.773, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.3, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00418, train/loss_prior=0.21, train/lr=2.07e-5, train/num_steps=35125, train/recon_cossim=0.842, train/recon_mse=0.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|                                                                                                           | 125/150 [1:45:20<20:47, 49.91s/it, test/blurry_pixcorr=0, test/loss=14.5, test/loss_clip_total=0.877, test/loss_prior=0.455, test/num_steps=126, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.8, test/test_fwd_pct_correct=0.777, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.17, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00462, train/loss_prior=0.206, train/lr=1.92e-5, train/num_steps=35406, train/recon_cossim=0.845, train/recon_mse=0.206]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|                                                                                                      | 126/150 [1:46:10<19:53, 49.71s/it, test/blurry_pixcorr=0, test/loss=13.4, test/loss_clip_total=0.881, test/loss_prior=0.416, test/num_steps=127, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.807, test/test_fwd_pct_correct=0.773, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.999, train/loss=6.19, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00263, train/loss_prior=0.206, train/lr=1.76e-5, train/num_steps=35687, train/recon_cossim=0.845, train/recon_mse=0.206]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|                                                                                                  | 127/150 [1:46:59<19:01, 49.65s/it, test/blurry_pixcorr=0, test/loss=15.2, test/loss_clip_total=0.894, test/loss_prior=0.476, test/num_steps=128, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.803, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.04, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00313, train/loss_prior=0.201, train/lr=1.62e-5, train/num_steps=35968, train/recon_cossim=0.849, train/recon_mse=0.201]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|                                                                                              | 128/150 [1:47:48<18:04, 49.31s/it, test/blurry_pixcorr=0, test/loss=13.7, test/loss_clip_total=0.89, test/loss_prior=0.428, test/num_steps=129, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.797, test/test_fwd_pct_correct=0.767, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.33, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00325, train/loss_prior=0.211, train/lr=1.48e-5, train/num_steps=36249, train/recon_cossim=0.841, train/recon_mse=0.211]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|                                                                                           | 129/150 [1:48:41<17:17, 49.40s/it, test/blurry_pixcorr=0, test/loss=14.9, test/loss_clip_total=0.894, test/loss_prior=0.466, test/num_steps=130, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.8, test/test_fwd_pct_correct=0.76, train/blurry_pixcorr=0, train/bwd_pct_correct=1, train/fwd_pct_correct=1, train/loss=6.32, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00017, train/loss_prior=0.211, train/lr=1.34e-5, train/num_steps=36530, train/recon_cossim=0.841, train/recon_mse=0.211]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|                                                                                     | 130/150 [1:49:31<16:52, 50.60s/it, test/blurry_pixcorr=0, test/loss=15.4, test/loss_clip_total=0.89, test/loss_prior=0.482, test/num_steps=131, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.8, test/test_fwd_pct_correct=0.773, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=5.95, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00393, train/loss_prior=0.198, train/lr=1.21e-5, train/num_steps=36811, train/recon_cossim=0.851, train/recon_mse=0.198]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|                                                                                 | 131/150 [1:50:20<15:54, 50.23s/it, test/blurry_pixcorr=0, test/loss=13.6, test/loss_clip_total=0.89, test/loss_prior=0.424, test/num_steps=132, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.793, test/test_fwd_pct_correct=0.773, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.999, train/loss=6.34, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00142, train/loss_prior=0.211, train/lr=1.09e-5, train/num_steps=37092, train/recon_cossim=0.841, train/recon_mse=0.211]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|                                                                             | 132/150 [1:51:10<14:59, 49.98s/it, test/blurry_pixcorr=0, test/loss=12.4, test/loss_clip_total=0.888, test/loss_prior=0.385, test/num_steps=133, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.797, test/test_fwd_pct_correct=0.773, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.999, train/loss=6.36, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00143, train/loss_prior=0.212, train/lr=9.74e-6, train/num_steps=37373, train/recon_cossim=0.84, train/recon_mse=0.212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|                                                                        | 133/150 [1:51:59<14:11, 50.06s/it, test/blurry_pixcorr=0, test/loss=13.3, test/loss_clip_total=0.88, test/loss_prior=0.414, test/num_steps=134, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.803, test/test_fwd_pct_correct=0.773, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00268, train/loss_prior=0.206, train/lr=8.65e-6, train/num_steps=37654, train/recon_cossim=0.844, train/recon_mse=0.206]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|                                                                    | 134/150 [1:52:49<13:16, 49.77s/it, test/blurry_pixcorr=0, test/loss=13.8, test/loss_clip_total=0.882, test/loss_prior=0.432, test/num_steps=135, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.81, test/test_fwd_pct_correct=0.773, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.21, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0045, train/loss_prior=0.207, train/lr=7.62e-6, train/num_steps=37935, train/recon_cossim=0.844, train/recon_mse=0.207]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|                                                                | 135/150 [1:53:38<12:23, 49.58s/it, test/blurry_pixcorr=0, test/loss=15.1, test/loss_clip_total=0.892, test/loss_prior=0.475, test/num_steps=136, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.81, test/test_fwd_pct_correct=0.767, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.03, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00438, train/loss_prior=0.201, train/lr=6.65e-6, train/num_steps=38216, train/recon_cossim=0.848, train/recon_mse=0.201]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|                                                            | 136/150 [1:54:29<11:33, 49.54s/it, test/blurry_pixcorr=0, test/loss=15.4, test/loss_clip_total=0.902, test/loss_prior=0.482, test/num_steps=137, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.78, test/test_fwd_pct_correct=0.767, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.999, train/loss=5.99, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00312, train/loss_prior=0.2, train/lr=5.75e-6, train/num_steps=38497, train/recon_cossim=0.85, train/recon_mse=0.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|                                                       | 137/150 [1:55:18<10:48, 49.89s/it, test/blurry_pixcorr=0, test/loss=13.3, test/loss_clip_total=0.903, test/loss_prior=0.412, test/num_steps=138, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.777, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.995, train/loss=5.92, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00789, train/loss_prior=0.197, train/lr=4.91e-6, train/num_steps=38778, train/recon_cossim=0.852, train/recon_mse=0.197]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|                                                   | 138/150 [1:56:09<09:56, 49.72s/it, test/blurry_pixcorr=0, test/loss=13.8, test/loss_clip_total=0.909, test/loss_prior=0.43, test/num_steps=139, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.78, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.994, train/fwd_pct_correct=0.994, train/loss=6.07, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00963, train/loss_prior=0.202, train/lr=4.13e-6, train/num_steps=39059, train/recon_cossim=0.848, train/recon_mse=0.202]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|                                               | 139/150 [1:56:59<09:11, 50.12s/it, test/blurry_pixcorr=0, test/loss=14.1, test/loss_clip_total=0.907, test/loss_prior=0.44, test/num_steps=140, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.78, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.06, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0033, train/loss_prior=0.202, train/lr=3.42e-6, train/num_steps=39340, train/recon_cossim=0.848, train/recon_mse=0.202]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|                                          | 140/150 [1:57:48<08:20, 50.01s/it, test/blurry_pixcorr=0, test/loss=15.1, test/loss_clip_total=0.908, test/loss_prior=0.473, test/num_steps=141, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.783, test/test_fwd_pct_correct=0.767, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.2, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00392, train/loss_prior=0.206, train/lr=2.78e-6, train/num_steps=39621, train/recon_cossim=0.845, train/recon_mse=0.206]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|                                      | 141/150 [1:58:37<07:27, 49.72s/it, test/blurry_pixcorr=0, test/loss=14.7, test/loss_clip_total=0.916, test/loss_prior=0.46, test/num_steps=142, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=5.93, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0062, train/loss_prior=0.197, train/lr=2.21e-6, train/num_steps=39902, train/recon_cossim=0.851, train/recon_mse=0.197]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|                                  | 142/150 [1:59:26<06:36, 49.52s/it, test/blurry_pixcorr=0, test/loss=15.6, test/loss_clip_total=0.915, test/loss_prior=0.489, test/num_steps=143, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.79, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.995, train/loss=5.77, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00698, train/loss_prior=0.192, train/lr=1.7e-6, train/num_steps=40183, train/recon_cossim=0.855, train/recon_mse=0.192]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|                              | 143/150 [2:00:15<05:45, 49.34s/it, test/blurry_pixcorr=0, test/loss=13.5, test/loss_clip_total=0.914, test/loss_prior=0.421, test/num_steps=144, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.793, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.995, train/loss=6.26, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00709, train/loss_prior=0.208, train/lr=1.25e-6, train/num_steps=40464, train/recon_cossim=0.842, train/recon_mse=0.208]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|                         | 144/150 [2:01:05<04:56, 49.46s/it, test/blurry_pixcorr=0, test/loss=14.1, test/loss_clip_total=0.913, test/loss_prior=0.441, test/num_steps=145, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.79, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.997, train/fwd_pct_correct=0.997, train/loss=6.05, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00478, train/loss_prior=0.201, train/lr=8.79e-7, train/num_steps=40745, train/recon_cossim=0.848, train/recon_mse=0.201]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|                     | 145/150 [2:01:54<04:06, 49.28s/it, test/blurry_pixcorr=0, test/loss=15.8, test/loss_clip_total=0.914, test/loss_prior=0.495, test/num_steps=146, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.999, train/fwd_pct_correct=0.999, train/loss=6.24, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00202, train/loss_prior=0.208, train/lr=5.71e-7, train/num_steps=41026, train/recon_cossim=0.843, train/recon_mse=0.208]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|                 | 146/150 [2:02:43<03:17, 49.32s/it, test/blurry_pixcorr=0, test/loss=13.7, test/loss_clip_total=0.913, test/loss_prior=0.425, test/num_steps=147, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.79, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.995, train/loss=6.24, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.007, train/loss_prior=0.208, train/lr=3.3e-7, train/num_steps=41307, train/recon_cossim=0.842, train/recon_mse=0.208]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|            | 147/150 [2:03:32<02:27, 49.23s/it, test/blurry_pixcorr=0, test/loss=12.8, test/loss_clip_total=0.914, test/loss_prior=0.396, test/num_steps=148, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.995, train/fwd_pct_correct=0.995, train/loss=6.08, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00716, train/loss_prior=0.203, train/lr=1.57e-7, train/num_steps=41588, train/recon_cossim=0.847, train/recon_mse=0.203]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|        | 148/150 [2:04:21<01:38, 49.27s/it, test/blurry_pixcorr=0, test/loss=14, test/loss_clip_total=0.914, test/loss_prior=0.437, test/num_steps=149, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.996, train/fwd_pct_correct=0.996, train/loss=6.28, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.00642, train/loss_prior=0.209, train/lr=5.08e-8, train/num_steps=41869, train/recon_cossim=0.842, train/recon_mse=0.209]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|    | 149/150 [2:05:11<00:49, 49.22s/it, test/blurry_pixcorr=0, test/loss=13.3, test/loss_clip_total=0.914, test/loss_prior=0.413, test/num_steps=150, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.04, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0026, train/loss_prior=0.201, train/lr=1.22e-8, train/num_steps=42150, train/recon_cossim=0.848, train/recon_mse=0.201]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 150/150 [2:05:20<00:00, 50.14s/it, test/blurry_pixcorr=0, test/loss=13.3, test/loss_clip_total=0.914, test/loss_prior=0.413, test/num_steps=150, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.787, test/test_fwd_pct_correct=0.77, train/blurry_pixcorr=0, train/bwd_pct_correct=0.998, train/fwd_pct_correct=0.998, train/loss=6.04, train/loss_blurry_cont_total=0, train/loss_blurry_total=0, train/loss_clip_total=0.0026, train/loss_prior=0.201, train/lr=1.22e-8, train/num_steps=42150, train/recon_cossim=0.848, train/recon_mse=0.201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Finished!===\n",
      "\n",
      "\n",
      "---saved /weka/proj-fmri/jonxu/MindEye_Imagery/train_logs/base/last ckpt!---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{model_name} starting with epoch {epoch} / {num_epochs}\")\n",
    "progress_bar = tqdm(range(epoch,num_epochs), ncols=1200, disable=(local_rank!=0))\n",
    "test_image, test_voxel = None, None\n",
    "mse = nn.MSELoss()\n",
    "l1 = nn.L1Loss()\n",
    "soft_loss_temps = utils.cosine_anneal(0.004, 0.0075, num_epochs - int(mixup_pct * num_epochs))\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    model.train()\n",
    "\n",
    "    fwd_percent_correct = 0.\n",
    "    bwd_percent_correct = 0.\n",
    "    test_fwd_percent_correct = 0.\n",
    "    test_bwd_percent_correct = 0.\n",
    "    \n",
    "    recon_cossim = 0.\n",
    "    test_recon_cossim = 0.\n",
    "    recon_mse = 0.\n",
    "    test_recon_mse = 0.\n",
    "\n",
    "    loss_clip_total = 0.\n",
    "    loss_blurry_total = 0.\n",
    "    loss_blurry_cont_total = 0.\n",
    "    test_loss_clip_total = 0.\n",
    "    \n",
    "    loss_prior_total = 0.\n",
    "    test_loss_prior_total = 0.\n",
    "\n",
    "    blurry_pixcorr = 0.\n",
    "    test_blurry_pixcorr = 0. # needs >.456 to beat low-level subj01 results in mindeye v1\n",
    "\n",
    "    # pre-load all batches for this epoch (it's MUCH faster to pre-load in bulk than to separate loading per batch)\n",
    "    voxel_iters = {} # empty dict because diff subjects have differing # of voxels\n",
    "    image_iters = torch.zeros(num_iterations_per_epoch, batch_size*len(subj_list), 3, 224, 224).float()\n",
    "    annot_iters = {}\n",
    "    perm_iters, betas_iters, select_iters = {}, {}, {}\n",
    "    for s, train_dl in enumerate(train_dls):\n",
    "        with torch.cuda.amp.autocast(dtype=data_type):\n",
    "            for iter, (behav0, past_behav0, future_behav0, old_behav0) in enumerate(train_dl):    \n",
    "                image0 = images[behav0[:,0,0].cpu().long()].float()\n",
    "                image_iters[iter,s*batch_size:s*batch_size+batch_size] = image0\n",
    "                \n",
    "                voxel0 = voxels[f'subj0{subj_list[s]}'][behav0[:,0,5].cpu().long()]\n",
    "                voxel0 = torch.Tensor(voxel0)\n",
    "                \n",
    "                if seq_len==1:\n",
    "                    voxel0 = voxel0.unsqueeze(1)\n",
    "                else:\n",
    "                    if seq_past>0:\n",
    "                        past_behavior = past_behav0[:,:(seq_past),5].cpu().long()\n",
    "                        past_voxel0 = voxels[f'subj0{subj_list[s]}'][past_behavior]\n",
    "                        past_voxel0[past_behavior==-1] = voxel0[torch.where(past_behavior==-1)[0]] # replace invalid past voxels \n",
    "                        past_voxel0 = torch.Tensor(past_voxel0)\n",
    "\n",
    "                        # if shared1000, then you need to mask it out \n",
    "                        for p in range(seq_past):\n",
    "                            mask = (past_behav0[:,p,-1] == 1) # [16,] bool\n",
    "                            index = torch.nonzero(mask.cpu()).squeeze()\n",
    "                            past_voxel0[index,p,:] = torch.zeros_like(past_voxel0[index,p,:])\n",
    "\n",
    "                    if seq_future>0:\n",
    "                        future_behavior = future_behav0[:,:(seq_future),5].cpu().long()\n",
    "                        future_voxel0 = voxels[f'subj0{subj_list[s]}'][future_behavior]\n",
    "                        future_voxel0[future_behavior==-1] = voxel0[torch.where(future_behavior==-1)[0]] # replace invalid past voxels \n",
    "                        future_voxel0 = torch.Tensor(future_voxel0)\n",
    "\n",
    "                        # if shared1000, then you need to mask it out \n",
    "                        for p in range(seq_future):\n",
    "                            mask = (future_behav0[:,p,-1] == 1) # [16,] bool\n",
    "                            index = torch.nonzero(mask.cpu()).squeeze()\n",
    "                            future_voxel0[index,p,:] = torch.zeros_like(future_voxel0[index,p,:])\n",
    "\n",
    "                    # concatenate current timepoint with past/future\n",
    "                    if seq_past > 0 and seq_future > 0:\n",
    "                        voxel0 = torch.cat((voxel0.unsqueeze(1), past_voxel0), axis=1)\n",
    "                        voxel0 = torch.cat((voxel0, future_voxel0), axis=1)\n",
    "                    elif seq_past > 0:\n",
    "                        voxel0 = torch.cat((voxel0.unsqueeze(1), past_voxel0), axis=1)\n",
    "                    else:\n",
    "                        voxel0 = torch.cat((voxel0.unsqueeze(1), future_voxel0), axis=1)\n",
    "\n",
    "                if epoch < int(mixup_pct * num_epochs):\n",
    "                    voxel0, perm, betas, select = utils.mixco(voxel0)\n",
    "                    perm_iters[f\"subj0{subj_list[s]}_iter{iter}\"] = perm\n",
    "                    betas_iters[f\"subj0{subj_list[s]}_iter{iter}\"] = betas\n",
    "                    select_iters[f\"subj0{subj_list[s]}_iter{iter}\"] = select\n",
    "\n",
    "                voxel_iters[f\"subj0{subj_list[s]}_iter{iter}\"] = voxel0\n",
    "\n",
    "                if iter >= num_iterations_per_epoch-1:\n",
    "                    break\n",
    "\n",
    "    # you now have voxel_iters and image_iters with num_iterations_per_epoch batches each\n",
    "    for train_i in range(num_iterations_per_epoch):\n",
    "        with torch.cuda.amp.autocast(dtype=data_type):\n",
    "            optimizer.zero_grad()\n",
    "            loss=0.\n",
    "\n",
    "            voxel_list = [voxel_iters[f\"subj0{s}_iter{train_i}\"].detach().to(device) for s in subj_list]\n",
    "            image = image_iters[train_i].detach()\n",
    "            image = image.to(device)\n",
    "\n",
    "            if use_image_aug: \n",
    "                image = img_augment(image)\n",
    "\n",
    "            clip_target = clip_img_embedder(image)\n",
    "            assert not torch.any(torch.isnan(clip_target))\n",
    "\n",
    "            if epoch < int(mixup_pct * num_epochs):\n",
    "                perm_list = [perm_iters[f\"subj0{s}_iter{train_i}\"].detach().to(device) for s in subj_list]\n",
    "                perm = torch.cat(perm_list, dim=0)\n",
    "                betas_list = [betas_iters[f\"subj0{s}_iter{train_i}\"].detach().to(device) for s in subj_list]\n",
    "                betas = torch.cat(betas_list, dim=0)\n",
    "                select_list = [select_iters[f\"subj0{s}_iter{train_i}\"].detach().to(device) for s in subj_list]\n",
    "                select = torch.cat(select_list, dim=0)\n",
    "\n",
    "            voxel_ridge_list = [model.ridge(voxel_list[si],si) for si,s in enumerate(subj_list)]\n",
    "            voxel_ridge = torch.cat(voxel_ridge_list, dim=0)\n",
    "\n",
    "            backbone, clip_voxels, blurry_image_enc_ = model.backbone(voxel_ridge)\n",
    "\n",
    "            if clip_scale>0:\n",
    "                clip_voxels_norm = nn.functional.normalize(clip_voxels.flatten(1), dim=-1)\n",
    "                clip_target_norm = nn.functional.normalize(clip_target.flatten(1), dim=-1)\n",
    "\n",
    "            if use_prior:\n",
    "                loss_prior, prior_out = model.diffusion_prior(text_embed=backbone, image_embed=clip_target)\n",
    "                loss_prior_total += loss_prior.item()\n",
    "                loss_prior *= prior_scale\n",
    "                loss += loss_prior\n",
    "\n",
    "                recon_cossim += nn.functional.cosine_similarity(prior_out, clip_target).mean().item()\n",
    "                recon_mse += mse(prior_out, clip_target).item()\n",
    "\n",
    "            if clip_scale>0:\n",
    "                if epoch < int(mixup_pct * num_epochs):                \n",
    "                    loss_clip = utils.mixco_nce(\n",
    "                        clip_voxels_norm,\n",
    "                        clip_target_norm,\n",
    "                        temp=.006,\n",
    "                        perm=perm, betas=betas, select=select)\n",
    "                else:\n",
    "                    epoch_temp = soft_loss_temps[epoch-int(mixup_pct*num_epochs)]\n",
    "                    loss_clip = utils.soft_clip_loss(\n",
    "                        clip_voxels_norm,\n",
    "                        clip_target_norm,\n",
    "                        temp=epoch_temp)\n",
    "\n",
    "                loss_clip_total += loss_clip.item()\n",
    "                loss_clip *= clip_scale\n",
    "                loss += loss_clip\n",
    "\n",
    "            if blurry_recon:     \n",
    "                image_enc_pred, transformer_feats = blurry_image_enc_\n",
    "\n",
    "                image_enc = autoenc.encode(2*image-1).latent_dist.mode() * 0.18215\n",
    "                loss_blurry = l1(image_enc_pred, image_enc)\n",
    "                loss_blurry_total += loss_blurry.item()\n",
    "\n",
    "                if epoch < int(mixup_pct * num_epochs):\n",
    "                    image_enc_shuf = image_enc[perm]\n",
    "                    betas_shape = [-1] + [1]*(len(image_enc.shape)-1)\n",
    "                    image_enc[select] = image_enc[select] * betas[select].reshape(*betas_shape) + \\\n",
    "                        image_enc_shuf[select] * (1 - betas[select]).reshape(*betas_shape)\n",
    "\n",
    "                image_norm = (image - mean)/std\n",
    "                image_aug = (blur_augs(image) - mean)/std\n",
    "                _, cnx_embeds = cnx(image_norm)\n",
    "                _, cnx_aug_embeds = cnx(image_aug)\n",
    "\n",
    "                cont_loss = utils.soft_cont_loss(\n",
    "                    nn.functional.normalize(transformer_feats.reshape(-1, transformer_feats.shape[-1]), dim=-1),\n",
    "                    nn.functional.normalize(cnx_embeds.reshape(-1, cnx_embeds.shape[-1]), dim=-1),\n",
    "                    nn.functional.normalize(cnx_aug_embeds.reshape(-1, cnx_embeds.shape[-1]), dim=-1),\n",
    "                    temp=0.2)\n",
    "                loss_blurry_cont_total += cont_loss.item()\n",
    "\n",
    "                loss += (loss_blurry + 0.1*cont_loss) * blur_scale #/.18215\n",
    "\n",
    "            if clip_scale>0:\n",
    "                # forward and backward top 1 accuracy        \n",
    "                labels = torch.arange(len(clip_voxels_norm)).to(clip_voxels_norm.device) \n",
    "                fwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_voxels_norm, clip_target_norm), labels, k=1).item()\n",
    "                bwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_target_norm, clip_voxels_norm), labels, k=1).item()\n",
    "\n",
    "            if blurry_recon:\n",
    "                with torch.no_grad():\n",
    "                    # only doing pixcorr eval on a subset of the samples per batch because its costly & slow to compute autoenc.decode()\n",
    "                    random_samps = np.random.choice(np.arange(len(image)), size=len(image)//5, replace=False)\n",
    "                    blurry_recon_images = (autoenc.decode(image_enc_pred[random_samps]/0.18215).sample/ 2 + 0.5).clamp(0,1)\n",
    "                    pixcorr = utils.pixcorr(image[random_samps], blurry_recon_images)\n",
    "                    blurry_pixcorr += pixcorr.item()\n",
    "\n",
    "            utils.check_loss(loss)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            lrs.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            if lr_scheduler_type is not None:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    if local_rank==0:\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(dtype=data_type): \n",
    "            for test_i, (behav, past_behav, future_behav, old_behav) in enumerate(test_dl):  \n",
    "                # all test samples should be loaded per batch such that test_i should never exceed 0\n",
    "                assert len(behav) == num_test\n",
    "\n",
    "                ## Average same-image repeats ##\n",
    "                if test_image is None:\n",
    "                    voxel = voxels[f'subj0{subj}'][behav[:,0,5].cpu().long()]\n",
    "                    \n",
    "                    if seq_len==1:\n",
    "                        voxel = voxel.unsqueeze(1)\n",
    "                    else:\n",
    "                        if seq_past>0:\n",
    "                            past_behavior = past_behav[:,:(seq_past),5].cpu().long()\n",
    "                            past_voxels = voxels[f'subj0{subj}'][past_behavior]\n",
    "                            if torch.any(past_behavior==-1).item(): # remove invalid voxels (-1 if there is no timepoint available)\n",
    "                                past_voxels[torch.where(past_behavior==-1)[0]] = 0\n",
    "\n",
    "                        if seq_future>0:\n",
    "                            future_behavior = future_behav[:,:(seq_future),5].cpu().long()\n",
    "                            future_voxels = voxels[f'subj0{subj}'][future_behavior]                    \n",
    "                            if torch.any(future_behavior==-1).item(): # remove invalid voxels (-1 if there is no timepoint available)\n",
    "                                future_voxels[torch.where(future_behavior==-1)[0]] = 0\n",
    "                            \n",
    "                        if seq_past > 0 and seq_future > 0:\n",
    "                            voxel = torch.cat((voxel.unsqueeze(1), past_voxels), axis=1)\n",
    "                            voxel = torch.cat((voxel, future_voxels), axis=1)\n",
    "                        elif seq_past > 0:\n",
    "                            voxel = torch.cat((voxel.unsqueeze(1), past_voxels), axis=1)\n",
    "                        else:\n",
    "                            voxel = torch.cat((voxel.unsqueeze(1), future_voxels), axis=1)\n",
    "\n",
    "                    image = behav[:,0,0].cpu().long()\n",
    "\n",
    "                    unique_image, sort_indices = torch.unique(image, return_inverse=True)\n",
    "                    for im in unique_image:\n",
    "                        locs = torch.where(im == image)[0]\n",
    "                        if len(locs)==1:\n",
    "                            locs = locs.repeat(3)\n",
    "                        elif len(locs)==2:\n",
    "                            locs = locs.repeat(2)[:3]\n",
    "                        assert len(locs)==3\n",
    "                        if test_image is None:\n",
    "                            test_image = images[im][None]\n",
    "                            test_voxel = voxel[locs][None]\n",
    "                        else:\n",
    "                            test_image = torch.vstack((test_image, images[im][None]))\n",
    "                            test_voxel = torch.vstack((test_voxel, voxel[locs][None]))\n",
    "\n",
    "                loss=0.\n",
    "                            \n",
    "                test_indices = torch.arange(len(test_voxel))[:300]\n",
    "                voxel = test_voxel[test_indices].to(device)\n",
    "                image = test_image[test_indices].to(device)\n",
    "                assert len(image) == 300\n",
    "\n",
    "                clip_target = clip_img_embedder(image.float())\n",
    "\n",
    "                for rep in range(3):\n",
    "                    voxel_ridge = model.ridge(voxel[:,rep],0) # 0th index of subj_list\n",
    "                    backbone0, clip_voxels0, blurry_image_enc_ = model.backbone(voxel_ridge)\n",
    "                    if rep==0:\n",
    "                        clip_voxels = clip_voxels0\n",
    "                        backbone = backbone0\n",
    "                    else:\n",
    "                        clip_voxels += clip_voxels0\n",
    "                        backbone += backbone0\n",
    "                clip_voxels /= 3\n",
    "                backbone /= 3\n",
    "\n",
    "                if clip_scale>0:\n",
    "                    clip_voxels_norm = nn.functional.normalize(clip_voxels.flatten(1), dim=-1)\n",
    "                    clip_target_norm = nn.functional.normalize(clip_target.flatten(1), dim=-1)\n",
    "                \n",
    "                # for some evals, only doing a subset of the samples per batch because of computational cost\n",
    "                random_samps = np.random.choice(np.arange(len(image)), size=len(image)//5, replace=False)\n",
    "                \n",
    "                if use_prior:\n",
    "                    loss_prior, contaminated_prior_out = model.diffusion_prior(text_embed=backbone[random_samps], image_embed=clip_target[random_samps])\n",
    "                    test_loss_prior_total += loss_prior.item()\n",
    "                    loss_prior *= prior_scale\n",
    "                    loss += loss_prior\n",
    "                    \n",
    "                    if visualize_prior:\n",
    "                        # now get unCLIP prediction without feeding it the image embed to get uncontaminated reconstruction\n",
    "                        prior_out = model.diffusion_prior.p_sample_loop(backbone[random_samps].shape, \n",
    "                                        text_cond = dict(text_embed = backbone[random_samps]), \n",
    "                                        cond_scale = 1., timesteps = 20)\n",
    "\n",
    "                        test_recon_cossim += nn.functional.cosine_similarity(prior_out, clip_target[random_samps]).mean().item()\n",
    "                        test_recon_mse += mse(prior_out, clip_target[random_samps]).item()\n",
    "                        \n",
    "                if clip_scale>0:\n",
    "                    loss_clip = utils.soft_clip_loss(\n",
    "                        clip_voxels_norm,\n",
    "                        clip_target_norm,\n",
    "                        temp=.006)\n",
    "\n",
    "                    test_loss_clip_total += loss_clip.item()\n",
    "                    loss_clip = loss_clip * clip_scale\n",
    "                    loss += loss_clip\n",
    "\n",
    "                if blurry_recon:\n",
    "                    image_enc_pred, _ = blurry_image_enc_\n",
    "                    blurry_recon_images = (autoenc.decode(image_enc_pred[random_samps]/0.18215).sample / 2 + 0.5).clamp(0,1)\n",
    "                    pixcorr = utils.pixcorr(image[random_samps], blurry_recon_images)\n",
    "                    test_blurry_pixcorr += pixcorr.item()\n",
    "\n",
    "                if clip_scale>0:\n",
    "                    # forward and backward top 1 accuracy        \n",
    "                    labels = torch.arange(len(clip_voxels_norm)).to(clip_voxels_norm.device) \n",
    "                    test_fwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_voxels_norm, clip_target_norm), labels, k=1).item()\n",
    "                    test_bwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_target_norm, clip_voxels_norm), labels, k=1).item()\n",
    "                \n",
    "                utils.check_loss(loss)                \n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "            # if utils.is_interactive(): clear_output(wait=True)\n",
    "            print(\"---\")\n",
    "\n",
    "            assert (test_i+1) == 1\n",
    "            logs = {\"train/loss\": np.mean(losses[-(train_i+1):]),\n",
    "                \"test/loss\": np.mean(test_losses[-(test_i+1):]),\n",
    "                \"train/lr\": lrs[-1],\n",
    "                \"train/num_steps\": len(losses),\n",
    "                \"test/num_steps\": len(test_losses),\n",
    "                \"train/fwd_pct_correct\": fwd_percent_correct / (train_i + 1),\n",
    "                \"train/bwd_pct_correct\": bwd_percent_correct / (train_i + 1),\n",
    "                \"test/test_fwd_pct_correct\": test_fwd_percent_correct / (test_i + 1),\n",
    "                \"test/test_bwd_pct_correct\": test_bwd_percent_correct / (test_i + 1),\n",
    "                \"train/loss_clip_total\": loss_clip_total / (train_i + 1),\n",
    "                \"train/loss_blurry_total\": loss_blurry_total / (train_i + 1),\n",
    "                \"train/loss_blurry_cont_total\": loss_blurry_cont_total / (train_i + 1),\n",
    "                \"test/loss_clip_total\": test_loss_clip_total / (test_i + 1),\n",
    "                \"train/blurry_pixcorr\": blurry_pixcorr / (train_i + 1),\n",
    "                \"test/blurry_pixcorr\": test_blurry_pixcorr / (test_i + 1),\n",
    "                \"train/recon_cossim\": recon_cossim / (train_i + 1),\n",
    "                \"test/recon_cossim\": test_recon_cossim / (test_i + 1),\n",
    "                \"train/recon_mse\": recon_mse / (train_i + 1),\n",
    "                \"test/recon_mse\": test_recon_mse / (test_i + 1),\n",
    "                \"train/loss_prior\": loss_prior_total / (train_i + 1),\n",
    "                \"test/loss_prior\": test_loss_prior_total / (test_i + 1),\n",
    "                }\n",
    "\n",
    "            # if finished training, save jpg recons if they exist\n",
    "            if (epoch == num_epochs-1) or (epoch % ckpt_interval == 0):\n",
    "                if blurry_recon:    \n",
    "                    image_enc = autoenc.encode(2*image[:4]-1).latent_dist.mode() * 0.18215\n",
    "                    # transform blurry recon latents to images and plot it\n",
    "                    fig, axes = plt.subplots(1, 8, figsize=(10, 4))\n",
    "                    jj=-1\n",
    "                    for j in [0,1,2,3]:\n",
    "                        jj+=1\n",
    "                        axes[jj].imshow(utils.torch_to_Image((autoenc.decode(image_enc[[j]]/0.18215).sample / 2 + 0.5).clamp(0,1)))\n",
    "                        axes[jj].axis('off')\n",
    "                        jj+=1\n",
    "                        axes[jj].imshow(utils.torch_to_Image((autoenc.decode(image_enc_pred[[j]]/0.18215).sample / 2 + 0.5).clamp(0,1)))\n",
    "                        axes[jj].axis('off')\n",
    "\n",
    "                    if wandb_log:\n",
    "                        logs[f\"test/blur_recons\"] = wandb.Image(fig, caption=f\"epoch{epoch:03d}\")\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        plt.show()\n",
    "                        \n",
    "                if use_prior and visualize_prior: # output recons every ckpt\n",
    "                    idx = np.random.randint(0, 3)\n",
    "                    print(f\"reconstructing... idx={idx}\")\n",
    "                    samples = utils.unclip_recon(prior_out[[idx]],\n",
    "                             diffusion_engine,\n",
    "                             vector_suffix)\n",
    "                    if wandb_log:\n",
    "                        logs[f\"test/orig\"] = wandb.Image(transforms.ToPILImage()(image[idx]),\n",
    "                                                           caption=f\"epoch{epoch:03d}\")\n",
    "                        logs[f\"test/recons\"] = wandb.Image(transforms.ToPILImage()(samples[0]),\n",
    "                                                           caption=f\"epoch{epoch:03d}\")\n",
    "                    if utils.is_interactive():\n",
    "                        plt.figure(figsize=(2,2))\n",
    "                        plt.imshow(transforms.ToPILImage()(image[idx]))\n",
    "                        plt.axis('off')\n",
    "                        plt.show()\n",
    "                        \n",
    "                        plt.figure(figsize=(2,2))\n",
    "                        plt.imshow(transforms.ToPILImage()(samples[0]))\n",
    "                        plt.axis('off')\n",
    "                        plt.show()\n",
    "\n",
    "            progress_bar.set_postfix(**logs)\n",
    "\n",
    "            if wandb_log: wandb.log(logs)\n",
    "            \n",
    "    # Save model checkpoint and reconstruct\n",
    "    if (ckpt_saving) and (epoch % ckpt_interval == 0):\n",
    "        save_ckpt(f'last')\n",
    "\n",
    "    # wait for other GPUs to catch up if needed\n",
    "    accelerator.wait_for_everyone()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n===Finished!===\\n\")\n",
    "if ckpt_saving:\n",
    "    save_ckpt(f'last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7e81ae3-171f-40ad-a3e8-24bee4472325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b4136-eebd-48ea-8552-9aecea23a797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "62aae01ef0cf7b6af841ab1c8ce59175c4332e693ab3d00bc32ceffb78a35376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
